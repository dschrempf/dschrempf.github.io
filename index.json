[{"categories":["Coding"],"contents":"Alle Jahre wieder \u0026hellip;\nI am not sure how far I get this year, but writing Haskell is just too much fun. Have a look at my solutions to the Advent of code, 2023.\nCheers!\nPS: I even added automatic fetching of the full input as well as the samples (see Fetch.hs). For example,\ncabal run fetch 1 # Fetch full input of day one. cabal run fetch 1 1 # Fetch sample one of day one. ","permalink":"https://dschrempf.github.io/coding/2023-12-02-advent-of-code-2023/","tags":null,"title":"Advent of code (2023)"},{"categories":["Linux"],"contents":"An update of my Tolino Shine 3 reader failed. The system recovery did not work aborting with the following error:\nBatterie fast leer! Ein-/Ausschalter druecken, Geraet mind. 2 h aufladen und neu starten. Low battery! Press the power button, charge the device for a minimum of 2 hours and restart. Weird. Charging did not help either. In fact, I am not not the only one experiencing this problem. Be sure to read the linked blog post, it contains important information. In particular, the battery check is flawed and the Tolino Shine 3 system recovery is broken!\nLuckily, opening the device is easy, and the Tolino Shine 3 uses a MicroSD card. So a working SD card image is all I need to fix the reader. I contacted the customer service; nope, they do not provide an image because there is a serial number stored on the card, and everybody needs a different one. Send it in, 48 EUR. (That\u0026rsquo;s actually quite cheap, but hey, they messed it up, not me. By the way, supposedly, if you delete the SD card, there is no way they can repair your Tolino).\nAnyways. I managed to fix the device. Here is what I did:\nOpen the Tolino. (It is quite easy using a thin plastic device; fun fact: I used a nose flute). Remove the SD card. Put the card into a computer; backup the complete SD card (e.g., using dd). If you like, create extra backups of partition 1 (boot), and partition 2 (recovery). Download TWRP for the Tolino Shine 3. Place the twrp.img onto recovery partition 2 (e.g., using dd). Get the update.zip from official Tolino website. Extract update.zip. Edit the script printing the \u0026ldquo;Low Battery\u0026rdquo; error (see above; rg for it). Remove the infamous battery check. Re-zip (use zip -r ../update.zip * to avoid the leading directory). Restart device and boot into recovery (this was automatic for me, since the system was broken). Use ADB to copy the patched zip file to the device (the internal memory was in /sdcard1 in my case). Install the zip file using TWRP. Like so, the signature is not checked and the \u0026ldquo;update\u0026rdquo; script succeeds. Boot into the Tolino and check if everything works. Create a backup of the working SD card; and store it somewhere extremely safe. Be happy and open a beer. Links:\nThe blog post that made it work for me. Thank you, Matthias! The best forum I found is MobileRead. See my empty thread and another hacking thread. Tolino hacking (not Tolino Shine 3) Android tools (XDA) (which are not required but I had to use them to find the boot and recovery partitions). ","permalink":"https://dschrempf.github.io/linux/2023-05-14-fixing-a-tolino-shine-3-ebook-reader/","tags":null,"title":"Fixing a Tolino Shine 3 ebook reader"},{"categories":["Emacs"],"contents":"Do you want to use Emacs for Java development? I suggest using the language server protocol with lsp-mode and lsp-java together with the Eclipse JDT language server (jdtls). And do you also want a declarative development environment without surprises? Use Nix Direnv, envrc.el, and a Nix Flake! I assume familiarity with these concepts. In the following, I will focus on the Java-related Emacs setup.\nThe reason of this post is that I have stumbled upon problems when using a declarative, project-specific configuration. In particular, lsp-java uses a global variable lsp-java-server-install-dir which specifies the installation directory of jdtls. Further, it uses global workspace and configuration directories which are jdtls specific settings; we want those to be project-specific.\nBut first things first. The following snippet defines a minimalist Nix Flake that provides a development environment for Java:\n# File \u0026#39;flake.nix\u0026#39;. { description = \u0026#34;Java development environment\u0026#34;; inputs.flake-utils.url = \u0026#34;github:numtide/flake-utils\u0026#34;; inputs.nixpkgs.url = \u0026#34;github:NixOS/nixpkgs/nixos-unstable\u0026#34;; outputs = { self, flake-utils, nixpkgs }: flake-utils.lib.eachDefaultSystem (system: let pkgs = nixpkgs.legacyPackages.${system}; in { devShells.default = with pkgs; mkShell { packages = [ # Gradle, Java development kit, and Java language server. gradle jdk jdt-language-server ]; # Environment variable specifying the plugin directory of # the language server \u0026#39;jdtls\u0026#39;. JDTLS_PATH = \u0026#34;${jdt-language-server}/share/java\u0026#34;; }; } ); } We also set up a directory environment file, and use it:\necho \u0026#34;use flake\u0026#34; \u0026gt; .envrc direnv allow direnv reload However, the language server will not work yet. We need to tell lsp-java about the location of jdtls and how to run it. This has proven to be difficult, if not arduous. The solution, however, is pretty easy.\nUse the wrapper script shipped with jdtls instead of a manual java --lots-of-options invocation like so:\n(after! lsp-java (defun lsp-java--ls-command () (list \u0026#34;jdt-language-server\u0026#34; \u0026#34;-configuration\u0026#34; \u0026#34;../config-linux\u0026#34; \u0026#34;-data\u0026#34; \u0026#34;../java-workspace\u0026#34;))) after! is a Doom Emacs macro that executes code after loading a feature. You can use other constructs, if you like. The function lsp-java--ls-command provides a list of strings which are concatenated and executed when running the language server. Here, we use the wrapper script jdt-language-server, and only specify the project-specific configuration and workspace directories. We put them in the parent directory of the Java project, because, well, see this weird Stack Overflow answer. Set lsp-java-server-install-dir in a hook using the environment variable JDTLS_PATH set by the Nix Flake shell:\n(after! cc-mode (defun my-set-lsp-path () (setq lsp-java-server-install-dir (getenv \u0026#34;JDTLS_PATH\u0026#34;))) (add-hook \u0026#39;java-mode-hook #\u0026#39;my-set-lsp-path)) Like so, everything works like a charm, and my experience with lsp-java has been great so far! We can have different versions of jdtls for different projects, and they do not even interfere with each other. Wow.\nIf you want, you can now set up a demo project from within Emacs using lsp-java-spring-initializer. After setting up the demo project, the directory structure is:\n/home/dominik/Scratch/java ├── config-linux -- Created by =jdtls=, see above. ├── demo -- Demo project. ├── .direnv ├── .envrc ├── flake.lock ├── flake.nix ├── .git ├── .gitignore └── java-workspace -- Created by =jdtls=, see above. 5 directories, 4 files In conclusion, we have a project-specific, declarative Java development setup. However, there is still some local state and cache created by Gradle or Maven, depending on which build tool you use. For example, I do have a ~/.gradle directory with lots of artifacts\u0026hellip; If you know how to tell Gradle or Maven to be project-specific, let me know!\n","permalink":"https://dschrempf.github.io/emacs/2023-03-02-emacs-java-and-nix/","tags":null,"title":"Emacs, Java, and Nix — An interesting journey"},{"categories":["Coding"],"contents":"Everybody posts their solutions in Haskell to the Advent of Code (described well on Wikipedia). So I thought I am going to join the crowd.\nHere are mine! I did clean the code after submission, but I did not change anything substantial such as algorithms or data structures.\n(Want some more? And \u0026mdash; well \u0026mdash; more?)\nIf you ask me, the solutions of Sheinxy and Scriptim are great! Also, do not miss the ones posted by Monday Morning Haskell, although they do have some boilerplate.\n","permalink":"https://dschrempf.github.io/coding/2022-12-02-advent-of-code-2022/","tags":null,"title":"Advent of Code (2022)"},{"categories":["Coding"],"contents":"\u0026lt;2023-02-27 Mon\u0026gt; Note: I have taken the application offline.\nI created a minimalist weather predicition application \u0026mdash; a short proof of concept and stake.\nThe main elements of the Haskell tech stack are:\nScotty: A web framework. Lucid: A domain specific language for HTML. Mcmc: A Markov chain Monte Carlo sampler. Other noteworthy components of this project:\nThe development environment is managed by the Nix package manager. The application is deployed using a Nix Flake. For details, have a look at the project source code.\nI deploy the application to my home server which is turned on roughly from 8am to 10pm CET. I mean, who wants to predict the weather during the night?\n","permalink":"https://dschrempf.github.io/coding/2022-12-02-weather-prediction-application/","tags":null,"title":"Weather prediction application"},{"categories":["Coding"],"contents":"We analyze the number of worldwide airline fatal accidents:\nYear 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 Fatalities 24 25 31 31 22 21 26 20 16 22 This table is an excerpt of Table 2.2 in Gelman, Andrew and Carlin, John B and Stern, Hal S and Rubin, Donald B (2014).\nWe assume that the number of fatal accidents \\(X\\) is Poisson distributed with fatal accident rate \\(\\lambda\\)\n\\begin{align} Pr(X=k|\\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}. \\end{align}\nThe maximum likelihood estimate of \\(\\lambda\\) is the mean of the fatalities, which is \\(23.8\\). However, we infer the probability distribution of \\(\\lambda\\) given the observed fatalities. Actually, we infer a function that is proportional to the probability distribution of \\(\\lambda\\) but is not a distribution because it does not integrate to \\(1.0\\). We call this function posterior function.\nWe know that the true mode of the posterior function should be at \\(\\lambda = 23.8\\), and so the mode of our estimate of the posterior function should be close. We use a Markov chain Monte Carlo (MCMC) sampler and Haskell.\nAlgorithm Markov chains are sequences of events with a peculiar property: the probability of each possible next event only depends on the state of the previous event. In particular, the probability does not depend on any events before the previous event. Markov chains are widely used in statistics, for example, to predict the weather. An interesting application of Markov chains is MCMC, a class of algorithms used to effectively sample from probability distributions.\nThis sounds theoretical and over-complicated. Why do we need a dedicated algorithm to sample from a probability distribution? Isn\u0026rsquo;t it easy to just pick more probable values more often than less probably values, and do so with the correct ratio?\nThe answer is: Yes, and this is exactly what MCMC samplers do. For example, the most famous Metropolis-Hastings-Green algorithm (Geyer, Charles J, 2011, an excellent introduction to MCMC by the way) samples new values from given, well-behaved proposal distributions, only to accept or reject these new values according to the actual probability distribution of interest.\nNote that standard probability distributions are heavily studied and there exist much faster, dedicated sampling methods. For example, see the computational methods to sample from the Poisson distribution or the normal distribution. Actually, the Metropolis-Hastings-Green algorithm makes use of these dedicated methods.\nImplementation In the following, we will implement the sampler using the mcmc library which I am developing. Here, I only briefly present the essential steps to run an MCMC sampler; please have a look at the documentation on Hackage, if you want to get a deeper understanding of the internals. Further, we use the random library, as well as the following imports:\n-- We need \u0026#39;void\u0026#39;. import Control.Monad -- I am developing the \u0026#39;mcmc\u0026#39; library. import Mcmc -- We need to sample random numbers; requires the \u0026#39;random\u0026#39; library. import System.Random The state space \\(I\\) of an MCMC sampler defines the possible values the Markov chain can attain. In our case \\(I\\) is the fatal accident rate \\(\\lambda\\), a floating point number:\ntype I = Double For a given fatal accident rate \\(\\lambda\\), the likelihood function is a product of Poisson probabilities with the observed fatalities:\nlh :: LikelihoodFunction I lh x = product [poisson x y | y \u0026lt;- fatalities] where fatalities = [24, 25, 31, 31, 22, 21, 26, 20, 16, 22] The LikehoodFunction I is a type synonym for I -\u0026gt; Log Double. Internally, we use probabilities in the log domain to avoid numerical underflow; see log-domain.\nWe need to tell the sampler how to propose new values. We do this using proposals. Here, we use two types:\na sliding proposal which adds random numbers to the current value of \\(\\lambda\\), and a scaling proposal which multiplies random values with the current value of \\(\\lambda\\). ppSl :: Proposal I ppSl = slideSymmetric 0.1 (PName \u0026#34;lambda\u0026#34;) (pWeight 1) Tune ppSc :: Proposal I ppSc = scaleUnbiased 0.1 (PName \u0026#34;lambda\u0026#34;) (pWeight 1) Tune There is some necessary boiler plate code about how large the proposal sizes are, how we name the proposals, or what weight we assign to the proposals. Tune tells the MCMC sampler to tune the proposal size according to established optimization criteria. In particular, the acceptance rates of proposals have optimal values that depend on the proposal dimension. The proposal dimension roughly corresponds to the number of independent parameters manipulated by the proposal. Tuning only happens during the first phase of the sampler which is called burn in (more about that below).\nWe collect the proposals in a cycle:\ncc :: Cycle I cc = cycleFromList [ppSl, ppSc] This modular definition of proposals, that is, of how to traverse the state space is one of the big strengths of the mcmc library. For complicated state spaces, we can use liftProposal and lenses to inform proposals about what part of the state they should change.\nNow, we define some monitors, so that we can observe the values of \\(\\lambda\\) attained by the Markov chain:\n-- \u0026#39;monitorDouble\u0026#39; is a simple monitor printing the value of a \u0026#39;Double\u0026#39;. monLambda :: MonitorParameter I monLambda = monitorDouble \u0026#34;lambda\u0026#34; -- We print the value of lambda to the standard output every 100 iterations. monStdOut :: MonitorStdOut I monStdOut = monitorStdOut [monLambda] 100 -- We log the value of lambda to a file more often. monFile :: MonitorFile I monFile = monitorFile \u0026#34;lambda\u0026#34; [monLambda] 3 mon :: Monitor I mon = Monitor monStdOut [monFile] [] We do not use batch monitors, so the last list of mon is empty.\nBefore running the chain, we need to provide some required settings:\nss :: Settings ss = Settings -- Provide an analysis name. (AnalysisName \u0026#34;poisson\u0026#34;) -- Burn in for 2000 generations. During burn in, the proposals are tuned -- automatically. This is called \u0026#34;auto tuning\u0026#34;. Here, auto tuning is -- performed every 200 iterations. (BurnInWithAutoTuning 2000 200) -- Number of actual iterations after burn in. (Iterations 30000) -- The trace of the Markov chain contains the attained values. In our case, -- it is a vector of fatal accident rates. Here, we tell the sampler to use -- the shortest trace possible. In our case, this will be a single value. -- However, when using batch monitors, or when auto tuning the masses of -- proposals based on Hamiltonian dynamics, the required length of the trace -- is larger than 1. masses. The trace length can also be set manually. TraceAuto -- Overwrite files created by a possible previous analysis. Overwrite -- Do not run chains in parallel. For the standard Metropolis-Hastings-Green -- algorithm, this has no effect. However, there are algorithms such as the -- MC3 algorithm with multiple chains that can run in parallel. Sequential -- Save the chain so that it can be continued (see \u0026#39;mcmcContinue\u0026#39;). Save -- Log to standard output and save the log to a file. LogStdOutAndFile -- Verbosity. Info Finally, we instantiate a chain using the Metropolis-Hastings-Green algorithm (MHG, mhg function) and run the MCMC sampler with the mcmc function:\nmain :: IO () main = do let g = mkStdGen 0 -- Set up the Markov chain. For computational efficiency (mutable vectors), -- this requires IO. al \u0026lt;- mhg ss noPrior lh cc mon 1.0 g -- We ignore the actual return value which is the complete Markov chain object -- using \u0026#39;void\u0026#39;. void $ mcmc ss al The complete code is available in the mcmc Git repository, see also the accompanying Cabal file.\nResults Using the above mentioned Git repository, you can run the code with\ncabal run poisson There is a lot of informative output. Further, log files poisson.mcmc.* and the monitor file poisson.lambda.monitor are created. Here, I will have a look at the posterior function of \\(\\lambda\\). To this end, I use Tracer to inspect the monitor file poisson.lambda.monitor:\nWe see in the summary statistics, that the estimated median is \\(23.88\\) which is close to the theoretical optimum of \\(23.8\\). We also observe that the posterior function is somewhat normal distributed.\nSummary and outlook We inferred the posterior function of the fatal accident rate of airlines in the 70s and 80s using a simple Poisson distribution, and an MCMC sampler in Haskell. There is a lot more we could do here. For example, we could improve our model using Poisson regression, we could look at advanced proposals such as proposals using Hamiltonian dynamics, or we could look at algorithms using parallel chains such as the Metropolic coupled MCMC (MC3) algorithm.\nIf this post spurred your interest, and you want to have a look at a real-life project: We use the mcmc library to perform phylogenetic dating. With McmcDate we infer the ages of speciations using molecular sequence data (DNA), molecular clocks, the age of fossils, gene transfers and much more! For example, we apply McmcDate to data from land plants (Harris, Brogan J. and Clark, James W. and Schrempf, Dominik and Szöllősi, Gergely J. and Donoghue, Philip C.J. and Hetherington, Alistair M. and Williams, Tom A., 2021).\nThe mcmc library is under development, and I am happy about your suggestions or comments; drop them on the repository on GitHub!\nReferences Gelman, Andrew and Carlin, John B and Stern, Hal S and Rubin, Donald B (2014). Bayesian data analysis, CRC Press.\nGeyer, Charles J (2011). {Introduction to Markov Chain Monte Carlo}, CRC press.\nHarris, Brogan J. and Clark, James W. and Schrempf, Dominik and Szöllősi, Gergely J. and Donoghue, Philip C.J. and Hetherington, Alistair M. and Williams, Tom A. (2021). Divergent evolutionary trajectories of bryophytes and tracheophytes from a complex common ancestor of land plants.\n","permalink":"https://dschrempf.github.io/coding/2022-06-28-sample-from-a-posterior-using-markov-chain-monte-carlo-algorithms-and-haskell/","tags":null,"title":"Parameter inference using Markov chain Monte Carlo algorithms and Haskell"},{"categories":null,"contents":"Personally, I do not collect any data.\nHowever:\nThis page is hosted by GitHub Pages which collects some data. Please see the privacy policy of GitHub. When accessing the website, you load some static yet external libraries: Website content: MathJax, and Font Awesome Free; Search: JQuery, MarkJs, and FuseJs. If you have questions, please contact me: .\n","permalink":"https://dschrempf.github.io/privacy/","tags":null,"title":"Privacy notice"},{"categories":["Coding"],"contents":"I started this encyclopedic overview because in the Markov chain Monte Carlo (MCMC) community many people call the same or similar concepts by very different names. Please let me know, if you have suggestions or comments, or if you would like to add some definitions or synonyms to this overview.\nBibliography Books The nomenclature here is taken from the excellent introduction to Markov chain Monte Carlo (MCMC) methods by Geyer, Charles J (2011), Chapter 1 in Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li (2011). More advanced topics such as population based MCMC methods are covered in Liang, Faming and Liu, Chuanhai and Carroll, Raymond (2011). See Arnaud Doucet and Nando de Freitas and Neil Gordon (2001) for sequential Monte Carlo algorithms. Articles Walter R. Gilks and Carlo Berzuini (2001) Del Moral, Pierre and Doucet, Arnaud and Jasra, Ajay (2006) Andrieu, Christophe and Doucet, Arnaud and Holenstein, Roman (2010) A. {Doucet} and A. M. {Johansen} (2011) Chopin, N. and Jacob, P. E. and Papaspiliopoulos, O. (2012) Heng, Jeremy and Bishop, Adrian N. and Deligiannidis, George and Doucet, Arnaud (2020) Articles tailored to a phylogenetic audience Bouchard-Côté, Alexandre and Sankararaman, Sriram and Jordan, Michael I. (2012) Vu Dinh and Aaron E Darling and Frederick A Matsen IV (2018) Mathieu Fourment and Brian C. Claywell and Vu Dinh and Connor McCoy and Frederick A. Matsen IV and Aaron E. Darling (2018) Necessary definitions Elementary updates are instructions about how to advance a Markov chain so that it possibly reaches a new state. That is, elementary updates specify how the chain traverses the state space. Elementary updates cannot be decomposed into smaller updates.\nElementary updates can be combined to form composite updates, a technique often referred to as composition. We use the word update to refer to either an elementary or a composite update.\nUpdates can also be executed in random order, a technique often referred to as mixture. Here, the word mixture is used in the sense of mixture models, and not in the sense of a chain reaching convergence.\nThe composition and mixture of elementary updates allows the specification of all (Is this true?, Please correct me if it is not.) MCMC algorithms involving a single chain. In particular, Gibbs samplers of all sorts can be specified using this procedure.\nRoughly, a Markov kernel is a map describing the probability density (for continuous spaces) or the probability mass (for discrete spaces) of updating one state to another.\nThe Metropolis-Hasings-Green algorithm specifies the acceptance probability of updates so that the stationary distribution of the resulting Markov chain is the desired posterior distribution.\nMany methods to improve convergence of MCMC samplers have been designed. Most notably, we have methods involving auxiliary variables and population based methods running various MCMC samplers in parallel.\nUnnecessary synonyms Proposal Update. Move Update. Metropolis update Update with uniform Markov kernel. Metropolis-Hastings update Update with arbitrary Markov kernel. Unnecessary synonyms and special cases of Metropolis-Hastings-Green MCMC methods Fixed scan algorithm MCMC sampler involving composition. Random scan algorithm MCMC sampler involving mixture. Random sequence scan algorithm MCMC sampler involving composition and mixture. Gibbs update Update with Metropolis-Hastings ratio of 1.0. That is, Gibbs updates are always accepted. Gibbs updates can be designed using conditional Markov kernels. Gibbs sampler MCMC sampler in which all of the elementary updates are Gibbs, combined either by composition (fixed scan), by mixture (random scan), or both (random sequence scan). Metropolis algorithm MCMC sampler in which all of the elementary updates are Metropolis, combined either by composition, mixture, or both (and the same \u0026ldquo;scan\u0026rdquo; terminology is used). Metropolis-Hastings algorithm MCMC sampler in which all of the elementary updates are Metropolis-Hastings, combined either by composition, mixture, or both (and the same \u0026ldquo;scan\u0026rdquo; terminology is used). Metropolis-within-Gibbs sampler The same as the preceding item. This name makes no sense at all since Gibbs is a special case of Metropolis-Hastings. Independence Metropolis-Hastings algorithm Special case of the Metropolis-Hastings algorithm in which the Markov kernel does not depend on the current state: \\(q(x, \\cdot)\\) does not depend on \\(x\\). Random-walk Metropolis-Hastings algorithm Special case of the Metropolis-Hastings algorithm in which the proposal has the form \\(x+e\\), where \\(e\\) is stochastically independent of the current state \\(x\\), so \\(q(x, y\\) has the form \\(f(y-x)\\). Reversible jump MCMC algorithm MCMC sampler including updates between different models possibly having a different set of parameters. However, these updates are in no way special. Special cases of auxiliary variable MCMC methods Data augmentation. Simulated annealing. Simulated tempering. Special cases of population based MCMC methods Sequential Monte Carlo. Parallel tempering. Metropolic-coupled MCMC (MC3) is Parallel tempering. References A. {Doucet} and A. M. {Johansen} (2011). {A tutorial on particle filtering and smoothing: fifteen years later}, Oxford: Oxford University Press.\nAndrieu, Christophe and Doucet, Arnaud and Holenstein, Roman (2010). Particle Markov chain Monte Carlo methods.\nBouchard-Côté, Alexandre and Sankararaman, Sriram and Jordan, Michael I. (2012). Phylogenetic inference via sequential monte carlo.\nChopin, N. and Jacob, P. E. and Papaspiliopoulos, O. (2012). SMC2: an efficient algorithm for sequential analysis of state space models.\nDel Moral, Pierre and Doucet, Arnaud and Jasra, Ajay (2006). Sequential Monte Carlo samplers.\nGeyer, Charles J (2011). {Introduction to Markov Chain Monte Carlo}, CRC press.\nHeng, Jeremy and Bishop, Adrian N. and Deligiannidis, George and Doucet, Arnaud (2020). Controlled sequential Monte Carlo.\nLiang, Faming and Liu, Chuanhai and Carroll, Raymond (2011). Advanced Markov chain Monte Carlo methods: learning from past samples, John Wiley \\\u0026amp; Sons.\nMathieu Fourment and Brian C. Claywell and Vu Dinh and Connor McCoy and Frederick A. Matsen IV and Aaron E. Darling (2018). Effective online bayesian phylogenetics via sequential monte carlo with guided proposals.\nBrooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li (2011). {Handbook of Markov Chain Monte Carlo}, CRC press.\nArnaud Doucet and Nando de Freitas and Neil Gordon (2001). Sequential Monte Carlo Methods in Practice, Springer New York.\nVu Dinh and Aaron E Darling and Frederick A Matsen IV (2018). Online Bayesian phylogenetic inference: theoretical foundations via sequential Monte Carlo.\nWalter R. Gilks and Carlo Berzuini (2001). Following a Moving Target-Monte Carlo Inference for Dynamic Bayesian Models.\n","permalink":"https://dschrempf.github.io/coding/2020-11-12-encyclopedia-of-markov-chain-monte-carlo-methods/","tags":null,"title":"Encyclopedia of Markov chain Monte Carlo methods"},{"categories":["Coding"],"contents":"The Algebraic Graphs Haskell library (Alga) is a fast, minimalist, and elegant approach to working with graphs that allows for equational reasoning about the correctness of algorithms. For reference, please also see the accompanying paper.\nThe advantages are:\nalgebraic graphs have a small core with just four graph construction primitives; the core has a mathematical structure characterized by a set of laws or properties. A directed graph in the mathematical sense is a set \\(V\\) of vertices \\(v_i\\) together with a set \\(E\\) of directed edges \\((v_i, v_j)\\), and is denoted \\((V,E)\\). The beauty about algebraic graphs is that they are not defined explicitly by lists of vertices and edges but in a recursive manner, similar to the definition of algebraic trees.\ndata Graph a = Empty | Vertex a | Overlay (Graph a) (Graph a) | Connect (Graph a) (Graph a) A graph is either empty ε, consists of a single vertex v, or it is somehow constructed by a combination of two sub-graphs using the binary construction operators Overlay \\((+)\\) or Connect \\((*)\\).\nThe overlay of two graphs is the union of vertices and edges\n\\begin{align} (V_1, E_1) + (V_2, E_2) = (V_1 \\cup V_2, E_1 \\cup E_2). \\end{align}\nThe connection of two graphs additionally creates edges between the vertices of the two graphs\n\\begin{align} (V_1, E_1) * (V_2, E_2) = (V_1 \\cup V_2, E_1 \\cup E_2 \\cup V_1 \\times V_2). \\end{align}\n\\((V_1 \\times V_2)\\) is the set of all edges from vertices of \\(V_1\\) to vertices of \\(V_2\\). For example, if \\(V_1 = \\{1,2\\}\\), and \\(V_2 = \\{3,4\\}\\), then\n\\begin{align} (V_1 \\times V_2) = \\{ (1,3), (1,4), (2,3), (2,4) \\}. \\end{align}\nOnly the connect operation allows the creation of new edges.\nThe algebraic properties of the the Graph data type are collected in a type class which is also called Graph.\nclass Graph g where type Vertex g empty :: g vertex :: Vertex g -\u0026gt; g overlay :: g -\u0026gt; g -\u0026gt; g connect :: g -\u0026gt; g -\u0026gt; g The definition involves a type synonym family, which is a function on the type level. The type synonym family specifies how the type of a vertex can be extracted from the data type instance.\nA valid Graph instance should fulfill the following laws:\n\\((G, +, \\epsilon)\\) is an idempotent commutative monoid. A monoid is an algebraic structure with an associative binary operation and an identity element. Idempotent means that \\(\\forall x \\in G: x + x = x\\). \\((G, \\ast, \\epsilon)\\) is a monoid. \\(\\ast\\) distributes over \\(+\\). That is, \\(1 \\ast (2 + 3) = (1 + 2) \\ast (1 + 3)\\). This structure is very close to an idempotent semiring. The differences are:\nThe identity elements \\(\\epsilon_+\\) and \\(\\epsilon_{\\ast}\\) are the same. Consequently, \\(\\epsilon_+\\) is not an annihilating element and it is wrong that \\( \\forall x \\in G: \\epsilon_+ \\ast x = 0 \\). Further, we have the decomposition law:\n\\begin{align} x \\ast y \\ast z = x \\ast y + x \\ast z + y \\ast z. \\end{align}\nThe strong decomposition law is a sufficient condition to induce the following statements.\nThe identities of \\(+\\) and \\(\\ast\\) are equal. \\(+\\) is idempotent. The binary operators \\(+\\) and \\(\\ast\\) are closed, and together with \\(\\epsilon\\) and \\(v\\), algebraic graphs are complete. In particular, we cannot create algebraic graphs that are not graphs in the mathematical sense, and all graphs can be represented using algebraic graphs.\nThe construction of a specific graph is not identifiable. Similar to \\(8=5+3\\) and \\(8=4+4\\), we can generate a graph by choosing two difference bipartitions and overlay them. More basic, \\( \\forall x \\in G\\) we have\n\\begin{align} x = x \\ast \\epsilon. \\end{align}\nThe canonical form of a given graph \\(g = (V_g, E_g)\\) is\n\\begin{align} g = \\sum_{v \\in V_g} v + \\sum_{(u,v) \\in E_g} u \\ast v. \\end{align}\nWe can define a partial order on graphs by\n\\begin{align} x \\le y \\iff x + y = y. \\end{align}\nThis is exactly the usual definition of a sub graph.\n\\begin{align} x \\subseteq y \\equiv x + y = y. \\end{align}\nA graph instance, additionally having multiplicative commutativity\n\\begin{align} x \\ast y = y \\ast x \\end{align}\nrepresents an undirected graph. In this case, the strong decomposition law also induces associativity of \\(\\ast\\).\nThe algebraic way of thinking about graphs and how to manipulate them was new to me. Nonsense graph objects cannot be created at all, and so, an important source of bugs is eliminated. This principle is an excellent example of the dogma parse, don\u0026rsquo;t validate, for which Haskell forms an excellent framework.\n","permalink":"https://dschrempf.github.io/coding/2019-11-21-algebraic-graphs/","tags":null,"title":"Algebraic graphs"},{"categories":null,"contents":"","permalink":"https://dschrempf.github.io/search/","tags":null,"title":"Search"},{"categories":null,"contents":"Deutsch [2022-09-17 Sat] Strompreisbremse: Ja nicht auf etwas verzichten müssen!, derStandard. Die Zukunft unserer Kinder scheint egal zu sein. Wir wollen jetzt billigen Strom. Österreich hängt kommenden Generationen mit der Strompreisbremse eine gewaltige Schuldenlast um.\n[2021-05-29 Sat] Elf Jahre an der Macht: Das Orbán-Regime der Günstlinge, derStandard. Viktor Orbán hat sich auf Kosten Ungarns mit gezielten Grenzüberschreitungen die unumschränkte Macht gesichert.\n[2019-08-17 Sat] Lärm: Je schneller, desto LAUTER!!!, derStandard. Wo kann man noch Ruhe finden?\n[2017-11-17 Fri] Appell für Umweltschutz: \u0026ldquo;Warnung an Menschheit\u0026rdquo; von 15.000 Forschern, derStandard. In acht von neun entscheidenden Problemfeldern hat es seit 1992 Rückschritte gegeben.\n[2017-11-13 Mon] Schriftsteller Elsberg über CRISPR/Cas9: Was, wenn Gott sich geirrt hat?, derStandard. In der postfaktischen Debatte über Gentechnik wird vermengt, was man auseinanderhalten sollte.\n[2017-11-06 Mon] Es gibt zu viele Messenger – und einen klar besten: Signal, derStandard. Nutzer sprechen mittlerweile über dutzende verschiedene Plattformen miteinander, am klügsten wäre jedoch die Einigung auf Signal.\nEnglish [2023-10-20 Fri] Why Haskell is important, TWEAG, Marko Karpov.\n[2022-09-01 Thu] Civil disobedience by scientists helps press for urgent climate action; nature climate change. A matching article on The Guardian: Scientists call on colleagues to protest climate crisis with civil disobedience. Maybe also check out the Extinction Rebellion.\n[2021-01-11 Mon] Polarization in Poland: A Warning From Europe, TheAtlantic.\n[2020-04-29 Wed] Pseudoscience and COVID-19 — we’ve had enough already, Nature.\nThere is some evidence that alternative treatments and placebo effects can relieve distress — a common justification for tolerating unproven alternative treatments. But it’s inappropriate to deceive people (even for their benefit) with magical thinking, and it is inappropriate for scientists to let such misinformation go unremarked.\n[2019-08-30 Fri] The Secret Shame of Middle-Class Americans, TheAtlantic. Nearly half of Americans would have trouble finding $400 to pay for an emergency. I’m one of them.\n[2017-06-27 Tue] Is the staggeringly profitable business of scientific publishing bad for science?, TheGuardian. It is an industry like no other, with profit margins to rival Google – and it was created by one of Britain’s most notorious tycoons: Robert Maxwell.\nEspañol [2022-06-16 Thu] No son tus hijos, no es tu jefe; es el sistema. Así se genera el agotamiento o ‘burnout’ parental, elPaís. Los tabúes sobre la maternidad impiden que muchas mujeres sepan qué les ocurre o que sientan que pueden hablar sobre ello con los demás.\n[2021-12-09 Thu] Así consigue un laboratorio multiplicar por 1.000 el precio de un medicamento, elPaís. Leadiant Biosciences ha subido de 14 céntimos a 140 euros la pastilla del tratamiento de una enfermedad rara aprovechándose del monopolio concedido por la UE.\n[2021-05-31 Mon] Viena, el éxito del urbanismo feminista, elPaís. A mediados del siglo pasado, un grupo de hombres de clase media y conductores definieron las bases urbanísticas de las ciudades. Como respuesta surgió el urbanismo feminista, modelo que pone a las personas en el centro. Viena lleva décadas aplicándolo y ahora es una de las ciudades más agradables y verdes del mundo, también una de las mejores para vivir.\n[2020-12-17 Thu] \u0026ldquo;La independencia periodística, el mejor negocio de los medios\u0026rdquo;, elPaís. La independencia es el valor más preciado para un medio de calidad.\n[2020-04-08 Wed] \u0026quot;¿Somos una Europa Unida o no? La única respuesta posible es ayudar a los países que lo necesitan\u0026quot;, elPaís. El jefe de la ciencia europea dimite en medio de la crisis desatada por el nuevo coronavirus.\n[2018-09-04 Tue] El genetista italiano que desmontó el concepto de raza, elPaís. “El racismo es un antiguo flagelo de la humanidad”. “Pensamos que la ciencia sea objetiva. La ciencia está modelada por la sociedad porque es una actividad humana productiva que necesita tiempo y dinero, pues está guiada y dirigida por aquellas fuerzas que en el mundo ejercen el control sobre el dinero y sobre el tiempo. Las fuerzas sociales y económicas determinan en larga medida lo que la ciencia hace y cómo lo hace”.\n[2016-09-22 Thu] “A veces, hasta los paranoicos tenemos razón”, elPaís. Los que me preocupan son todos esos jóvenes ignorantes que pasan de todo porque dicen que no tienen nada que ocultar. Es ese tipo de gente que no se preocupa por el mundo en el que vive, porque se violen los derechos, las libertades que muchos antes defendieron en la Constitución. Me preocupa la pasividad que veo a mi alrededor.\n","permalink":"https://dschrempf.github.io/links/","tags":null,"title":"Links to newspaper articles"},{"categories":["Coding"],"contents":"I have been working on Markov chains for quite a while now and wanted to assess how Haskell can deal with simulating a simple, discrete chain.\nMany sources can be found online. The code presented here is partly taken from a question on stackoverflow. However, I was unsatisfied with the nomenclature and parts of the code. So I refactored most of it. Also, there is a Haskell library markov-chain, which I am unsatisfied with because of code readability (it\u0026rsquo;s pretty abstruse). Furthermore, I looked through a lengthy post about using Markov chains to simulate interaction of magnetic spins using the Ising model. The concept of a Markov chain is explained well in this article but I believe that the example is too complicated to understand in a reasonable amount of time. Also, the Repa package is used to represent the transition matrices. This seemed a little bit of an overkill to me, so I decided to go with maps.\nYou can also download the source code of the following post.\nIn this example, we will handle sentences with words. So our states are words which are strings. It is also convenient to introduce some type synonyms.\nmodule Main where import qualified Control.Monad.Random as R import qualified Data.Map as M -- | For better readability of the code, it is convenient to distinguish between -- the source and the target. type Source = String type Target = String -- | Transition from \u0026#39;Source\u0026#39; to \u0026#39;Target\u0026#39; observed in a sample. type Transitions = [(Source, Target)] -- | A \u0026#39;Target\u0026#39; with associated frequency. type TargetF = (Target, Rational) As mentioned before, the transition matrix is represented using a map. This might not be very efficient but it is easy to understand. The keys are just all the words that we can start from. The values are, for each source, the targets that we can jump to and their respective frequencies in the data.\ntype TransitionMatrix = M.Map Source [TargetF] This function is the heart of the simulation. For a given transition probability matrix and an initial string add a new word until a stop condition is reached. Here, the stop condition is the end of a sentence (a period \u0026ldquo;.\u0026rdquo;).\ngenerateSequence :: (R.MonadRandom m) =\u0026gt; TransitionMatrix -\u0026gt; String -\u0026gt; m String generateSequence tm s -- We have to test first, if the string is not null, otherwise \u0026#39;last\u0026#39; throws -- an exception. | not (null s) \u0026amp;\u0026amp; last s == \u0026#39;.\u0026#39; = return s | otherwise = do s\u0026#39; \u0026lt;- R.fromList $ tm M.! s ss \u0026lt;- generateSequence tm s\u0026#39; -- Only add a space after another word. return $ if null s then ss else s ++ \u0026#34; \u0026#34; ++ ss The next functions are used to fill the transition matrix given a list of observed transitions.\n-- | Add a target with its frequency to a list of targets with their -- frequencies. addTargetF :: TargetF -\u0026gt; [TargetF] -\u0026gt; [TargetF] addTargetF (t, f) ts = case lookup t ts of Nothing -\u0026gt; (t, f) : ts Just n -\u0026gt; (t, n+f) : filter notT ts where notT (r, _) = r /= t -- | Add more targets and their frequencies to a list of targets with their -- frequencies. This function is needed because \u0026#39;M.insertWith\u0026#39; requires an -- inserting function of type (a -\u0026gt; a -\u0026gt; a). addTargetFs :: [TargetF] -\u0026gt; [TargetF] -\u0026gt; [TargetF] addTargetFs tsA tsB = foldr addTargetF tsB tsA -- | Convert the observed transitions to the transition rate matrix. transitionsToMatrix :: Transitions -\u0026gt; TransitionMatrix transitionsToMatrix = foldr insert M.empty where insert t = M.insertWith addTargetFs (fst t) [(snd t, 1.0)] Now, we need a collection of samples and a way to retrieve all the observed transitions. The start of sentences is a little bit tricky. We kind of introduce a new state here, the empty string \u0026ldquo;\u0026rdquo;, which is followed by the first words of the provided sentences.\n-- | Collect all transitions from one word to the next. getTransitions :: [String] -\u0026gt; Transitions getTransitions (s:ss) = zip (\u0026#34;\u0026#34;:ws) ws ++ getTransitions ss where ws = words s getTransitions _ = [] -- | A collection of samples. samples :: [String] samples = [ \u0026#34;I am a monster.\u0026#34; , \u0026#34;I am a rock star.\u0026#34; , \u0026#34;I want to go to Hawaii.\u0026#34; , \u0026#34;I want to eat a hamburger.\u0026#34; , \u0026#34;I have a really big headache.\u0026#34; , \u0026#34;Haskell is a fun language.\u0026#34; , \u0026#34;Go eat a big hamburger.\u0026#34; , \u0026#34;Markov chains are fun to use.\u0026#34; ] And that\u0026rsquo;s already it. We can combine and execute our functions in the following way.\nmain :: IO () main = do s \u0026lt;- generateSequence (transitionsToMatrix $ getTransitions samples) \u0026#34;\u0026#34; print s E.g.,\n\u0026gt; main \u0026#34;I am a big hamburger.\u0026#34; Of course, the next step is to remove the String type dependency so that we can use our chain for arbitrary types. Then, we might try to convert our code into simulating a continuous-time Markov process, but this is another topic.\n","permalink":"https://dschrempf.github.io/coding/2018-02-10-markov-chains-in-haskell/","tags":null,"title":"Markov chains in Haskell"},{"categories":["Linux"],"contents":"Sometimes you discover online resources that you want to remember and share. These tutorials by the developers of iptables (mainly Paul \u0026lsquo;Rusty\u0026rsquo; Russell) are one of those gems. They discuss how the internet works, how packets can be adequately filtered and how a firewall can be setup.\nEnjoy!\n","permalink":"https://dschrempf.github.io/linux/2017-09-13-networking-tutorials/","tags":null,"title":"Networking HOWTOs"},{"categories":["Linux"],"contents":"[2019-03-01 Fri] See comment below; some Linux operating systems already provide native support for the Marvell RAID controller in legacy mode.\nMarvell SATA controller Recently I purchased an HPE ProLiant MicroServer Gen10 which comes with the Marvell SATA controller 88SE9230, also called Marvell Storage Utility (MSU). As far as I know, this controller has an ARM chip to provide RAID 0 (non-redundant combination of disks), RAID 1 (straight mirroring) or RAID 10 (a combination of RAID 0 and RAID 1).\nNeither Marvell nor HPE do provide drivers for generic Linux systems but they do provide a package for ClearOS which uses the Red Hat Package Manager (RPM).\nInitially, I tried to manage the RAID using the Marvell BIOS utility which can be accessed by the EFI shell. The BIOS utility and the user guide can be downloaded from the HPE support center. However, this procedure is slow and complicated, especially if the server is headless, as in my case. Furthermore, monitoring the disks with SMART data is also impossible. So I decided to invest some time in amending the ClearOS package for Arch Linux and provide an AUR package.\nMarvell controller package I had serious trouble running the original scripts and daemons because they are (a) written for ClearOS and (b) expect the generic but outdated SCSI kernel module sg to be loaded. I provide replacements with the same functionality:\nMSUAgent - The MSU Event Manager. MSUWebServer - The MSU Web Server (manual access at port 8045). MSUStart - A small script to access the web interface. These scripts also pull the sg module in case it is not loaded.\nFor my purposes however (I do not need a web interface), the MSU client mvcli, which is located in the folder /opt/marvell/storage/cli is all I need. Don\u0026rsquo;t forget to manually load the sg module, which sets up the SCSI devices for this script, e.g., with\nsudo modprobe -a sg Then, the SMART data can be retrieved, e.g., with\nsudo /opt/marvell/storage/cli/mvcli smart -p 0 Awesome :-)!\nIn the course of this project, I also stumbled upon other very useful SCSI related software: lsscsi, sg3_utils, sdparm, hdidle.\nI am still having trouble with monitoring temperature (e.g., CPU temperature), please leave a note if you know an easy way to achieve this.\n","permalink":"https://dschrempf.github.io/linux/2017-09-05-hpe-microserver-msu/","tags":null,"title":"Marvell Storage Utility on HPE ProLiant MicroServer Gen10"},{"categories":["Coding"],"contents":"Folds are complicated themselves, but monadic folds always have blown my mind. In what follows, I try to dissect foldlM for a specific example.\nMonadic folds can be used to perform a series of actions that depend on the previous output. The following function produces an action b from a value a also taking into account the output of the previous action b.\nf :: (b -\u0026gt; a -\u0026gt; m b) And here the definition of foldlM (which is the same as foldM).\nfoldlM :: (Foldable t, Monad m) =\u0026gt; (b -\u0026gt; a -\u0026gt; m b) -\u0026gt; b -\u0026gt; t a -\u0026gt; m b foldlM f z0 xs = foldr f\u0026#39; return xs z0 where f\u0026#39; x k z = f z x \u0026gt;\u0026gt;= k Let\u0026rsquo;s have a look at an example. The following function performs n jumps of a Markov chain starting from a given State s (an integer) according to a transition probability matrix ProbMatrix p (don\u0026rsquo;t worry about the state space, or the state space size, it does not matter). At the moment, I am not sure how to access or store the actual chain. This could be done by an equivalent of scanl for general monads, which I was unable to find.\njumpN :: (Monad m) =\u0026gt; State -\u0026gt; ProbMatrix -\u0026gt; Int -\u0026gt; m State jumpN s p n = foldM jump s (replicate n p) jump :: (Monad m) =\u0026gt; State -\u0026gt; ProbMatrix -\u0026gt; m State And specifically, with p being any transition probability matrix\njumpN 0 p 2 = foldM jump 0 [p, p] Now we use the definition of foldM\njumpN 0 p 2 = foldr f\u0026#39; return [p, p] 0 where f\u0026#39; x k z = jump z x \u0026gt;\u0026gt;= k which leads to\njumpN 0 p 2 = f\u0026#39; p (foldr f\u0026#39; return [p]) 0 = f\u0026#39; p (f\u0026#39; p (foldr f\u0026#39; return []) 0 = f\u0026#39; p (f\u0026#39; p (return)) 0 = f\u0026#39; p (f\u0026#39; p return) 0 = jump 0 p \u0026gt;\u0026gt;= (f\u0026#39; p return) And finally, we got what we wanted. This is the first time, that we see that first, we perform a jump from zero and use the output to feed it to the next jump.\njumpN 0 p 2 = jump 0 p \u0026gt;\u0026gt;= (f\u0026#39; p return) = do s\u0026#39; \u0026lt;- jump 0 p f\u0026#39; p return s\u0026#39; = do s\u0026#39; \u0026lt;- jump 0 p (jump s\u0026#39; p \u0026gt;\u0026gt;= return) = do s\u0026#39; \u0026lt;- jump 0 p s\u0026#39;\u0026#39; \u0026lt;- jump s\u0026#39; p return s\u0026#39;\u0026#39; Holy crap, I am not sure if understanding this was worth the pain :-).\n","permalink":"https://dschrempf.github.io/coding/2017-07-20-folding-around-monads-in-haskell/","tags":null,"title":"Happy folding around monads in Haskell"},{"categories":["Linux"],"contents":"I like a lot of stuff that Google is doing, especially that it supports open source. However, I really dislike their attitude towards user privacy. That is why I decided to get rid of Google on my Android phone. However, I had to solve some problems in order to keep user-friendliness at a high level and to be able to use all applications that I need.\nThe main issues are:\nWhich ROM do I use? How do I install software and keep it up to date? How do I synchronize all my contacts and calendar? Can I replace applications that do not run without Google Play Services? The answers are:\nCyanogenmod without Open GApps I have been using Cyanogenmod for quite some time now and I am very happy with it. After a complete backup, I formatted every possible partition on my phone and did a clean reinstall without Open GApps. This left me with a Google-less Android install.\nApplication management Use F-Droid. For applications that are not available in F-Droid, use a service that provides APK files of Google Play Store applications.\nThis is the main drawback, because this service has to be trusted in that it does not alter the APK files in any way. I decided to use APKPure because it comes with an application that can update all installed applications. I compared the md5 check sums of randomly chosen APK files from APKPure with the one from the Google Play Store and could not find any differences. This problem of completely trusting an unknown organization is still bugging me but I did not find another solution so far (especially because all application stores are incomplete).\nContact and calendar For contact and calendar synchronization, I use a Raspberry Pi with Nextcloud (or Owncloud) together with DavDroid on the phone (which is available on F-Droid). I am sure there are other services available that do not require an extensive server setup like this one.\nReplacement of Google applications I replaced Google Maps with OsmAnd; Gmail with the native Android mail client; I never used Google Now nor Hangouts nor any other Google application.\nSo far, this was way easier than I thought. Ironically, a local application that provides information about public transport was the only one that complained about Google Play Services being non-existent. That\u0026rsquo;s when I dived into this issue and found microG, an open source library that provides replacements for a lot of functions usually provided by Google Play Services.\nmicroG The setup on Cyanogenmod with Android 6.0.1 is tough because system spoofing needs to be available. This can be done using Haystack or Xposed (do not follow both instruction sets).\nInstallation of Haystack A detailed explanation can be found on the GitHub page.\nInstallation of Xposed With F-Droid, install Xposed Downloader. With Xposed Downloader, download the latest Xposed framework and the Xposed Installer. In Recovery mode, install the latest Xposed framework (always wipe cache). Wipe cache and reboot; check if the Xposed framework is working correctly (start Xposed installer). With Xposed, download FakeGApps and activate it; reboot. Installation of microG Services Core With F-Droid, activate the microG repository. With F-Droid, install microG Services Core, microG Services Framework and a network location backend (e.g., MozillaNlpbackend). With microG, open settings and check if spoofing support is enabled (Self-Check). With microG, enable everything and also the network location provider backend. And yea, it works! If you have installed applications that use Google Cloud Messaging (like Signal) before, you have to either reinstall them, or re-register to the Google servers, otherwise message delivery may be delayed. Conclusion Installing Android without Google Play Services was way easier than I thought. However, to enable applications that require certain features like the messaging or the location interface of Google Play Services, extensive tinkering is necessary.\n","permalink":"https://dschrempf.github.io/linux/2016-08-05-android-without-google/","tags":null,"title":"Get rid of Google"},{"categories":["Linux"],"contents":"Autojump is a cd command that learns! It enables you to easily navigate directories from the command line:\nAutojump on GitHub It is readily available in most Linux distributions. The sole thing that has to be done manually is sourcing a script in your .bashrc.\nsource /etc/profile.d/autojump.sh Jumping around with j is awesome :-)!\n","permalink":"https://dschrempf.github.io/linux/2016-05-20-autojump/","tags":null,"title":"Autojump"},{"categories":["Coding"],"contents":"[2016-04-09 Sat] I extended my set of C++ programs to include a simulator for generic continuous-time Markov chains. I.e., any transition rate matrix can be used.\nIf you are interested, just get the GitHub repository and compile the whole set of programs with make all. Documentation can be found in the doc/ folder (check the CTMC class).\nThere is a sample program src/moran_model_boundary_mutation, that runs the Moran model with boundary mutation (De Maio, N., Schrempf, D., \u0026amp; Kosiol, C. (2015). PoMo: An Allele Frequency-Based Approach for Species Tree Estimation. Systematic Biology, 64(6), 1018–1031. https://doi.org/10.1093/sysbio/syv048).\nUsing the chain is as easy as:\n// Define a GNU Scientific Library Matrix object. gsl_matrix * my_transition_rate_matrix = alloc_and_set_matrix(); CTMC my_chain(my_transition_rate_matrix, number_of_states); my_chain.run(a_specific_time); // Now we print some output. my_chain.print_hitting_times(std::cout); my_chain.print_invariant_distribution(std::cout); If you want to log the path of the chain, you have to activate the log path upon initialization:\nCTMC my_chain(my_transition_rate_matrix, number_of_states, true); // Print the path. my_chain.print_path(std::cout); Logging the path is disabled by default because it uses a lot of memory.\n","permalink":"https://dschrempf.github.io/coding/2016-04-09-continuous-time-markov-chain/","tags":null,"title":"A simulator for continuous-time Markov chains"},{"categories":["Linux"],"contents":"Did you ever get sick of typing the IP of your SSH server. There is an incredible feature of SSH that saves you a lot of time typing host names, IP addresses or passwords.\nLogin with SSH key First, you want to create your own SSH key so that your server accepts your login without any password.\n# Create an SSH key (use the standard path). Be careful, if you do # not set a passphrase, anybody that has access to your computer can # log into servers that have been set up to accept your key. ssh-keygen # Copy the key on your server. ssh-copy-id yourusername@yourserver.example.com # Try it out and be happy! ssh yourusername@yourserver.example.com Use ~/.ssh/config Now, it is getting better; edit or create the file ~/.ssh.config:\n#~/.ssh/config Host server HostName yourserver.example.com User yourusername Try to log into yourserver (now aliased server):\nssh server Wow, that was fast.\nProxyCommand And it can get better. Very often, the computer privatecomputer that you want to log in, is only accessible from the local network but not from the outside. However, you have access to server which, in turn has access to private.\nHmm, normally, you would need to\n# Log into the server. ssh yourusername@yourserver.example.com # Wait. Enter password. Wait. ssh privateusername@privatecomputer.local # Wait. Enter password. Wait. # That sucks. We can setup SSH keys so that we do not have to enter passwords\nfrom home to server (we already did that); from server to privatecomputer.local (you can do that now, if you want). However, we can also do something much more awesome. Put this into your ~/.ssh/config:\n#~/.ssh/config Host server HostName yourserver.example.com User yourusername Host private ProxyCommand ssh -q server -W privatecomputer.local:22 User privateusername And try it out:\nssh private Wow.\n","permalink":"https://dschrempf.github.io/linux/2016-04-09-ssh-config/","tags":null,"title":"Configure SSH"},{"categories":["Music"],"contents":"In my free time I love to make music and that\u0026rsquo;s why I am participating in the choir Cantus Novus Wien. We are about 40 people and perform sacred as well as secular music pieces.\nAudio samples Audio samples can be found on Soundcloud.\nA short quote from the homepage (in German) Der Cantus Novus Wien besteht aus engagierten Sängerinnen und Sängern, die am Wiener Diözesankonservatorium für Kirchenmusik zusammenfinden. Das gemeinsame, lebendige Singen zielt auf hohe musikalische Qualität; ein Schwerpunkt ist dabei zeitgenössische Chormusik mit Uraufführungen von Auftragswerken österreichischer Komponisten wie Wolfgang Sauseng, Ruth McGuire, Wolfgang Reisinger, Markus Pfandler und Wolfram Wagner.\nSeit einigen Jahren etabliert sich die Zusammenarbeit mit skandinavischen Künstlern. So gestaltete der Cantus Novus Wien mehrere Konzerte und CD-Aufnahmen gemeinsam mit Musikern und Komponisten aus Schweden und Finnland. Eine Erwähnung verdient das Konzert im Wiener Stephansdom im Mai 2011 gemeinsam mit dem Lidingö Motettkör, dem Originalchor aus dem schwedischen Kinofilm „Wie im Himmel“. Es folgte eine Konzertreise nach Stockholm im Juni 2012.\nZum Repertoire zählen auch große, klassische Chorwerke wie Händels \u0026ldquo;Israel in Ägypten\u0026rdquo; und \u0026ldquo;Messias\u0026rdquo;, Josef Haydns \u0026ldquo;Schöpfung\u0026rdquo; und das \u0026ldquo;Requiem\u0026rdquo; von Mozart. Der Cantus Novus Wien gestaltet immer wieder Gottesdienste, Hochzeiten und kirchliche Veranstaltungen. Regelmäßig werden Chorreisen für Konzerte mit Chören aus dem In- und Ausland unternommen.\n","permalink":"https://dschrempf.github.io/music/2015-08-31-cantus-novus/","tags":null,"title":"Cantus Novus Wien"},{"categories":["Emacs"],"contents":"Introduction Erroneous source code can be a nasty issue to tackle. Print statements that inform you about the states of variables are handy but sometimes they are unable to represent the intrinsic structure of the code. Debuggers allow you to run your code step by step, display and watch variables and see what is going on inside another program while it executes.\nThe GNU poject debugger Here, we will use the GNU project debugger (GDB), because it is freely available, very actively developed and can be used on many operating systems. It can\nstart your program, specifying anything that might affect its behavior; make your program stop on specified conditions; examine what has happened, when your program has stopped; change things in your program, so you can experiment with correcting the effects of one bug and go on to learn about another. GDB in Emacs To debug our program, we will use Emacs and C source code, although gdb can be used from the command line and can debug many different languages.\nA good overview about debugging in Emacs with GDB can be found in the Emacs manual.\nA short step-by-step guide:\nOpen and save a new file hello.c with the following contents:\n#include \u0026lt;stdio.h\u0026gt; int main(int argc, char* argv[]) { int i; printf(\u0026#34;hello world\\n\u0026#34;); for ( i=0;i\u0026lt;10;++i) { printf(\u0026#34;%d \\n\u0026#34;,i); } return 0; } Compile it with M-x compile; enter the command gcc -Wall -g hello.c -o hello. Usually, it is very helpful to compile your source code with debugging flags (e.g., -g for gcc), so that nothing is optimized out by the compiler.\nActivate the graphical debugging environment with M-x gdb-many-windows.\nStart the debugger with M-x gdb; enter the command gdb -i=mi hello.\nFrom withing the Grand Unified Debugger (GUD) buffer, you can run (r) the program to its end or to the first break point, start (start) and run in until the beginning of the main procedure. You can execute the program line-by-line (n) or step into functions with s.\nBreakpoints can be set from withing the source buffer by clicking on the fringe or with C-x C-a C-b.\nCustomize GDB To permanently set the nice GDB user interface layout, put\n(setq gdb-many-windows t) into your .emacs file. I have also written a function, that facilitates the starting of the debugger:\n(defvar gdb-my-history nil \u0026#34;History list for dom-gdb-MYPROG.\u0026#34;) (defun dom-gdb-MYPROG () \u0026#34;Debug MYPROG with `gdb\u0026#39;.\u0026#34; (interactive) (let* ((wd \u0026#34;/path/to/working/directory\u0026#34;) (pr \u0026#34;/path/to/executable\u0026#34;) (dt \u0026#34;/path/to/datafile\u0026#34;) (guess (concat \u0026#34;gdb -i=mi -cd=\u0026#34; wd \u0026#34; --args \u0026#34; pr \u0026#34; -s \u0026#34; dt)) (arg (read-from-minibuffer \u0026#34;Run gdb (like this): \u0026#34; guess nil nil \u0026#39;gdb-my-history))) (gdb arg))) Window management Upon debugging a program with many source files, GDB displays new source files in (random?) windows in your Emacs frame. This is especially tedious if you use gdb-many-windows. I have written a function dom-gdb-restore-windows, that resets the display and fixes the window layout:\n(defun dom-gdb-restore-windows () \u0026#34;Restore GDB session.\u0026#34; (interactive) (if (eq gdb-many-windows t) (gdb-restore-windows) (dom-gdb-restore-windows-gud-io-and-source))) (defun dom-gdb-restore-windows-gud-io-and-source () \u0026#34;Restore GUD buffer, IO buffer and source buffer next to each other.\u0026#34; (interactive) ;; Select dedicated GUD buffer. (switch-to-buffer gud-comint-buffer) (delete-other-windows) (set-window-dedicated-p (get-buffer-window) t) (when (or gud-last-last-frame gdb-show-main) (let ((side-win (split-window nil nil t)) (bottom-win (split-window))) ;; Put source to the right. (set-window-buffer side-win (if gud-last-last-frame (gud-find-file (car gud-last-last-frame)) (gud-find-file gdb-main-file))) (setq gdb-source-window side-win) ;; Show dedicated IO buffer below. (set-window-buffer bottom-win (gdb-get-buffer-create \u0026#39;gdb-inferior-io)) (set-window-dedicated-p bottom-win t)))) (defun dom-gdb-display-source-buffer () \u0026#34;Display gdb source buffer if it is set.\u0026#34; (interactive) (when (or gud-last-last-frame gdb-show-main) (switch-to-buffer (if gud-last-last-frame (gud-find-file (car gud-last-last-frame)) (gud-find-file gdb-main-file)))) (delete-other-windows)) ","permalink":"https://dschrempf.github.io/emacs/2015-06-24-debugging-with-emacs-and-gdb/","tags":null,"title":"Debugging with Emacs and GDB"},{"categories":["Linux"],"contents":"Does this sound familiar to you: You come back from a holiday with your family or friends and want to merge photos taken with 4 different cameras. However, somebody forgot to adjust the date (or did not set the daylight saving time accordingly). Hmm.\nThis problem can be solved easily. exiv2 is a program to read and write Exif image metadata and image comments. It offers a very easy command line interface and shortcuts to batch rename files (e.g., by time and date) or to change Exif flags.\nThe exiv2 homepage.\nExamples from the manual Some examples from the manual (man exiv2):\nexiv2 *.jpg Prints a summary of the Exif information for all JPEG files in the directory. exiv2 rename img_1234.jpg Renames img_1234.jpg (taken on 13-Nov-05 at 22:58:31) to 20051113_225831.jpg. exiv2 -r':basename:_%Y%m' rename img_1234.jpg Renames img_1234.jpg to img_1234_200511.jpg. exiv2 -et img1.jpg img2.jpg Extracts the Exif thumbnails from the two files into img1-thumb.jpg and img2-thumb.jpg. Adjust date and time We use the adjust switch from above:\nad | adjust Adjust Exif time stamps by the given time. Time adjustment is in the format [-]HH[:MM[:SS]]. Examples: 1 adds one hour, 1:01 adds one hour and one minute, -0:00:30 subtracts 30 seconds. An example:\nexiv2 adjust -a 1 *.jpg adds one hour to the time stamp of all JPG files in the working directory.\nBatch rename After you have adjusted the time stamps of the different cameras, you may want to rename the files, e.g.:\nexiv2 rename *.jpg renames all JPG files in the working directory to date_time.jpg, something very useful.\n","permalink":"https://dschrempf.github.io/linux/2015-04-25-exiv2-command-line-power/","tags":null,"title":"exiv2 command line power"},{"categories":["Linux"],"contents":"Introduction Recently, I have explained how to configure BitTorrent Sync over an SSH SOCKS proxy. However, due to various problems with BTSync, I tried Syncthing and I am very satisfied with it.\nAdvantages that I have experienced so far:\nopen source; publicly available synchronization protocol; very reliable if the configuration is fine; it\u0026rsquo;s a young project with motivated developers; it is fast (if enough CPU is available). Disadvantages that I have experienced so far:\nneeds more CPU (this is an issue if you are using devices with very old or slow hardware, e.g., a Raspberry Pi); the configuration is more tedious. The general setup is very well explained on the project homepages:\nhttps://syncthing.net/ and https://github.com/syncthing/syncthing. However, I have the problem, that my computer at work (clientA) is behind a firewall and not exposed to the public. In order to circumvent the firewall, we need a clientB that has full internet access, runs an SSH server and is accessible by clientA; then we can set up SSH such that it forwards connection requests from clientA to the outside and the other way around; check it out.\nThe idea We will use SSH port forwarding to map a port on clientA (let it be port 22111) to a port on the NAT router at my.router.hostname (here I will use port 22222). The router has to redirect the port to the clientC that listens for incoming connections at this specific port with Syncthing (port 20000 here).\nIn more detail, after the configuration below, the port localhost:22111 on clientA will point to a random port on clientB. There, the SSH server redirects the traffic to another random outgoing port and forwards it to my.router.hostname:22222. You still need to setup your router so that it forwards incoming connections to clientC:20000 (many router port forwarding tutorials are available online).\nThis way, we can circumvent the firewall that prevents direct access to my.router.hostname:22222.\nThe setup In order for this to work, you need SSH access from clientA to clientB (let\u0026rsquo;s assume that your user name is user). clientB needs to run an SSH server and have full access to the internet.\nThe forwarding from clientA to the router at my.router.hostname is done by the following SSH command:\nssh -N -vvv -L 22111:my.router.hostname:22222 user@clientB -N Do not open an interactive session (no commands can be entered at prompt). -vvv Increase verbosity to a high level, so that you can debug problems if you have any (can be removed later). -L This tells SSH to use the SSH server at clientB to map the local (-L) port 22111 on the client that runs the SSH command (in this case clientA) to port 22222 on my.router.hostname. Hence, if localhost:22111 is accessed at clientA, it gets forwarded to the NAT router which in turn has to be set up to forward incoming requests at port number 22222 to , e.g., clientC:22000. It is important to notice that the forwarding specification (for both, local and remote forwards) consists of 3 parts p1:host:p2. p1 is the port on the client that executes the SSH command; host is the host seen from the SSH server (e.g., clientB) and not from the client executing the command; p2 is the port on host seen from the SSH server. I.e., ssh -L 123:localhost:456 ssh_server forwards port 123 on the client executing the SSH command to port 456 on ssh_server.\nTest the setup The setup can be tested very easily and efficiently with the following method (this method can also be used with other software or ports).\nClose all running Syncthing processes on both sides. Tell clientC to listen on port 22000 by running nc -l -p 22000 on clientC. Access port 22111 on clientA by running nc -v localhost 22111 on clientA. Type some stuff into the terminal at clientA and hope that it is printed at clientC. If everything works, you can remove the -vvv flag, add a -q flag which tells SSH to be quiet and run the SSH port forwarding at boot.\nssh -N -q -L 22111:my.router.hostname:22222 user@clientB A good blog article about port forwarding.\nFurthermore, the port forwarding has to be started before Syncthing starts, otherwise there be dragons. I have written a small script that waits some time to start the port forwarding as well as a script that does the same for syncthing.service and syncthing-inotify.service.\nRemote port forwarding Furthermore, if you want to reach clientA from home, remote port forwarding can also be done. However, I did not need this and did not follow it up, e.g.:\nssh -N -q -R 22000:localhost:22200 clientB This would tell clientB to forward incoming requests at port 22200 to the client that executes the SSH command; in this case, clientA. Take care, GatewayPorts has to be set to yes.\nAmazing stuff Something to think about: Assume a working SSH server on clientC that is accessible by clientA (maybe only via clientB). Suppose, that the IP address of the router is 192.168.1.1 (seen from clientC; local area network). What does the following command (executed on clientA) achieve?\nssh -L 12345:192.168.1.1:80 clientC Try to access localhost:12345 in your browser at clientA and watch the pure awesomeness!\n","permalink":"https://dschrempf.github.io/linux/2015-04-22-syncthing/","tags":null,"title":"Syncthing with SSH Port Forwarding"},{"categories":["Emacs"],"contents":"Recently, I stumbled upon two nice Emacs minor modes.\nHelm mode Helm mode offers an incremental completion and selection narrowing framework. It will help you to find what you\u0026rsquo;re looking for in Emacs (like buffers, files, commands etc). Resources and discussions can be found at the following homepages:\ndevelopment and installation instructions at the Helm mode GitHub page; the Emacs initialization files and configuration of the Helm maintainer; a good overview of the features and a sample configuration. I can recommend to use the TAB key for completion and not for other actions. You can bind the TAB key back to helm-execute-persistent-action with\n;; Bind TAB to complete stuff. (define-key helm-map (kbd \u0026#34;TAB\u0026#34;) \u0026#39;helm-execute-persistent-action) ;; Rebind `helm-select-action\u0026#39; (originally bound to TAB). (define-key helm-map (kbd \u0026#34;C-j\u0026#34;) \u0026#39;helm-select-action) I had used Ido mode extensively before I switched to Helm mode. I must admit that the first thought was: too heavy and, oh, I miss the insertion with RET as well as that Ido remembers which files I had visited earlier. Also, completion cannot be used when looking for commands with helm-M-x. However, with Helm mode I enjoy most that I get an overview of what is out there. That is what I miss with Ido mode. Try it out yourself!\nHydra mode Hydra mode makes Emacs key bindings stick around so that they can be used without modifiers. It also displays them on the screen, so that rarely used shortcuts can be remembered without looking into the configuration files again (and again and again). It is very useful!\nCheck it out:\nsource code and introduction at Hydra mode on GitHub; some blog entries of the creator at (or emacs irrelevant). ","permalink":"https://dschrempf.github.io/emacs/2015-04-04-helm-hydra-modes/","tags":null,"title":"Emacs Helm and Hydra minor modes"},{"categories":["Coding"],"contents":"I maintain a Github repository that contains a bunch of very basic C++ programs that use Markov chains and other types of simulations to infer basic statistical parameters. The applications mainly focus on Population Genetics problems, although this is not always the case. At the moment, the list of programs is:\nbookshelf.cpp Bookshelf Markov chain brownian_motion_mcmc.cpp Simulate standard Brownian motion (Wiener process) coin_toss_mcmc.cpp Run a coin toss MCMC simulation cube_mcmc.cpp Simulation of a Markov chain that moves around the eight vertices of a cube ehrenfest_mcmc.cpp Simulate gas particles in a divided box general_discrete_distributions.cpp Given K discrete events with different probabilities P[k], produce a random value k consistent with its probability general_discrete_markov_chain.cpp Simulate a general discrete Markov chain with a given transition probability matrix P genetic_drift.cpp Simulate genetic drift hitchhiking.c Simulate hitchhiking along a positively selected locus stepping_stone_model.cpp Simulate Stepping Stone Model with a Markov chain Please check out the detailed documentation on the github repository.\n","permalink":"https://dschrempf.github.io/coding/2015-03-26-popgen-cpp-programs/","tags":null,"title":"Population genetics C++ programs"},{"categories":["Linux"],"contents":"\u0026lt;2015-04-22 Wed\u0026gt; I have switched from BitTorrent Sync to Syncthing. Reasons are:\nthe synchronization was not reliable (synchronization stalled sometimes; every update leads to a re-synchronization of all files); the corporate policy is not to my liking (a Pro version is available; the free version only supports a limited amount of folders and clients; it is not sure if it will stay free in the future). Please also refer to the blog entry that describes how to configure Syncthing with SSH port forwarding.\nIntroduction \u0026lt;2015-01-30 Fri\u0026gt; BitTorrent Sync is a nice program that lets you sync two clients using advanced peer-to-peer technology. It can be a very good replacement for Dropbox if you do not want to share files with others (although you could still use Dropbox for file sharing with others). Especially so, because it does not save any of your data on a server and synchronization is encrypted. Furthermore, it can be installed very easily on Linux (and even on a Mac and on Windows). Please see the installation instructions on their homepage.\nThe problem I had is that one of my clients (say client A) is behind a firewall. In order to circumvent it, we need a client B that has full access to the internet and that is accessible by client A; then we ca set up an SSH SOCKS proxy; check it out.\nSetup of SSH tunnel In order for this to work, you need SSH access from client A to client B. Client B needs to have access to the internet. Then you can setup a dynamic SSH tunnel at client A with:\nssh -vvv -N -D 1080 username@clientB -vvv Increase verbosity to a high level, so that you can debug problems if you have any (can be removed later). -N Do not open an interactive session (no commands can be entered at prompt). -D 1080 Dynamically forward all requests to localhost:1080 to client B (act as a SOCKS proxy on port 1080; if you are interested please see, e.g., port forwarding). If this worked out, every process on client A that accesses localhost:1080 will be forwarded to client B that is outside the firewall. I.e., you could also tell Firefox to use this SOCKS proxy so that you can access sites that you cannot otherwise. Actually this is a very good idea to test if the SOCKS proxy works in general.\nBTSync setup Now, BTSync should automatically find this SOCKS proxy (because it is using the standard port 1080; my BTSync version is 1.4.106) and uses it to circumvent the firewall. The very good and informative debug output of the SSH tunnel can be used to identify possible problems. A sample configuration file looks like this:\n\u0026lt;2015-04-01 Wed\u0026gt; The automatic detection of the SOCKS proxy did not work anymore (BTSync version 2.0.93). I have adjusted the configuration file below.\n{ \u0026#34;device_name\u0026#34; : \u0026#34;username@clientA\u0026#34;, \u0026#34;listening_port\u0026#34; : 0, // 0 - randomize port. /* The storage_path dir contains auxilliary app files if no storage_path field: .sync dir created in the directory where binary is located. otherwise user-defined directory will be used. */ \u0026#34;storage_path\u0026#34; : \u0026#34;/home/username/.btsync\u0026#34;, // Set location of pid file. \u0026#34;pid_file\u0026#34; : \u0026#34;/home/username/.btsync/btsync.pid\u0026#34;, // Do not use UPnP for port mapping. \u0026#34;use_upnp\u0026#34; : false, // limits in kB/s. 0 - no limit. \u0026#34;download_limit\u0026#34; : 0, \u0026#34;upload_limit\u0026#34; : 0, // Proxy configuration \u0026#34;proxy_type\u0026#34; : \u0026#34;socks4\u0026#34;, // Valid types: \u0026#34;socks4\u0026#34;, \u0026#34;socks5\u0026#34;, \u0026#34;http_connect\u0026#34;. Any other value means no proxy \u0026#34;proxy_addr\u0026#34; : \u0026#34;127.0.0.1\u0026#34;, // IP address of proxy server. \u0026#34;proxy_port\u0026#34; : 1080, // Do not use the webui. \u0026#34;webui\u0026#34; : { \u0026#34;listen\u0026#34; : \u0026#34;0.0.0.0:8889\u0026#34; }, /* !!! If you set shared folders in config file WebUI will be DISABLED !!! Shared directories specified in config file override the folders previously added from WebUI. */ \u0026#34;shared_folders\u0026#34; : [ { \u0026#34;secret\u0026#34; : \u0026#34;MYSECRET\u0026#34;, // required field - use --generate-secret in command line to create new secret \u0026#34;dir\u0026#34; : \u0026#34;/home/username/BTSync\u0026#34;, // * required field \u0026#34;use_relay_server\u0026#34; : true, // use relay server when direct connection fails \u0026#34;use_tracker\u0026#34; : true, \u0026#34;use_dht\u0026#34; : false, \u0026#34;search_lan\u0026#34; : true, \u0026#34;use_sync_trash\u0026#34; : true, // enable SyncArchive to store files deleted on remote devices \u0026#34;overwrite_changes\u0026#34; : false, // restore modified files to original version, ONLY for Read-Only folders \u0026#34;known_hosts\u0026#34; : // specify hosts to attempt connection without additional search [ ] } ] } ","permalink":"https://dschrempf.github.io/linux/2015-01-30-btsync/","tags":null,"title":"BitTorrent Sync over SSH proxy"},{"categories":["Coding"],"contents":"Suppose we observe 58 heads out of 100 coin tosses. Now, we want to know the probability of tossing a head \\(\\theta\\). A maximum likelihood guess would be \\(\\theta = 0.58\\) because then, the probability of observing 58 heads\n\\begin{align} P(58 \\mathrm{ heads}) = {100 \\choose 58} (0.58)^{58} (0.42)^{42} \\end{align}\nis greatest (an example of the binomial distribution).\nHowever, we could also use a Bayesian approach to calculate the posterior distribution of the probability \\(\\theta\\) (i.e., the probability that \\(\\theta\\) is a certain value conditioned on our observation).\nThe following C++ code does exactly this (the last column is the posterior).\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;iomanip\u0026gt; #include \u0026lt;math.h\u0026gt; #include \u0026lt;gsl/gsl_rng.h\u0026gt; // Run a coin toss MCMC simulation. // User interface. // Observation. int n_tosses = 100; int n_heads = 58; int n_tails = n_tosses - n_heads; // MCMC settings. int n_iter = 10000; int print_every = 500; double delta = 0.1; void fix_width_cout_str (std::string s) { std::cout \u0026lt;\u0026lt; std::setw(10) \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(2)\u0026lt;\u0026lt; s \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } void fix_width_cout_dbl (double d) { std::cout \u0026lt;\u0026lt; std::setw(10) \u0026lt;\u0026lt; std::fixed \u0026lt;\u0026lt; std::setprecision(2)\u0026lt;\u0026lt; d \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } int main (int argc, char *argv[]) { const gsl_rng_type * t; gsl_rng * r; double theta; // The probability of tossing a head. double posterior[100]; // The posterior. gsl_rng_env_setup(); t = gsl_rng_default; r = gsl_rng_alloc (t); gsl_rng_set (r, 1); // Pick a first guess from the prior distribution (uniform prior). // Here, the prior does not really effect the posterior. However, // it kicks in, when the likelihood ratio for acceptance is // calculated (see below). theta = gsl_rng_uniform (r); std::cout \u0026lt;\u0026lt; \u0026#34;Start MCMC.\u0026#34; \u0026lt;\u0026lt; std::endl; fix_width_cout_str(\u0026#34;iteration\u0026#34;); fix_width_cout_str(\u0026#34;theta_old\u0026#34;); fix_width_cout_str(\u0026#34;theta_pri\u0026#34;); fix_width_cout_str(\u0026#34;ln_tot\u0026#34;); fix_width_cout_str(\u0026#34;pr_of_acc\u0026#34;); fix_width_cout_str(\u0026#34;theta_new\u0026#34;); std::cout \u0026lt;\u0026lt; std::endl; // Initialize posterior. for (int i = 0; i \u0026lt; 100; i++) { posterior[i] = 0.0; } for (int i = 0; i \u0026lt; n_iter; i++) { // Acceptance ratio. double acc; double ln_likelihood_ratio; double ln_prior_ratio; double ln_proposal_ratio; double ln_tot; ////////////////////////////// // Propose a new theta. // Uniform, symmetric jump algorithm (Metropolis algorithm). // The jump algorithm influences the runtime (How many // proposals are accepted?) but it should not change the // posterior; this can be proven for the Metropolos and // the Metropolis-Hastings (non-symmetric jumps) algorithm. double old_theta = theta; double rn = gsl_rng_uniform (r); double theta_prime = theta + (rn - 0.5) * delta; if (theta_prime \u0026lt; 0.0) theta_prime = - theta_prime; if (theta_prime \u0026gt; 1.0) theta_prime = 2.0 - theta_prime; ////////////////////////////// // Accept theta_prime? // Calculate the natural logarithm of the likelihood // ratios of the new proposal to the old one. It consists // of: // 1. The likelihood ratio due to the model. // 2. The ratio of the prior (this is, where the prior // comes in). If the likelihood ratio of the model is // flat (i.e., ln_likelihood_ratio ~= 0.0), the prior is // very informative; something that we do not want in // general. // 3. The ratio of the proposal (the jumping algorithm). // This is, how we incorporate non-symmetric jumping // algorithms, so that they do not change the posterior. ln_likelihood_ratio = (n_heads*log(theta_prime) + n_tails*log(1.0-theta_prime)) - (n_heads*log(theta) + n_tails*log(1.0-theta)); ln_prior_ratio = 0.0; ln_proposal_ratio = 0.0; ln_tot = ln_likelihood_ratio + ln_prior_ratio + ln_proposal_ratio; // Circumvent underflow error. if (ln_tot \u0026lt; -300.0) acc = 0.0; else if (ln_tot \u0026gt; 0.0) acc = 1.0; else acc = exp (ln_tot); // Accept with probability acc. double u = gsl_rng_uniform (r); if (u \u0026lt; acc) { theta = theta_prime; posterior[(int)(theta*100)] += 1.0; } ////////////////////////////// //Log results. if (i % print_every == 0) { fix_width_cout_dbl (i); fix_width_cout_dbl (old_theta); fix_width_cout_dbl (theta_prime); fix_width_cout_dbl (ln_tot); fix_width_cout_dbl (acc); fix_width_cout_dbl (theta); std::cout \u0026lt;\u0026lt; std::endl; } } std::cout \u0026lt;\u0026lt; \u0026#34;MCMC finished.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; std::endl; // Normalize posterior. double sum = 0.0; for (int i = 0; i \u0026lt; 100; i++) { sum += posterior[i]; } for (int i = 0; i \u0026lt; 100; i++) { posterior[i] = posterior[i]/sum; } for (int i =0 ; i \u0026lt; 100; i++) { std::cout \u0026lt;\u0026lt; \u0026#34;Theta between \u0026#34;; std::cout \u0026lt;\u0026lt; std::setw(3) \u0026lt;\u0026lt; i; std::cout \u0026lt;\u0026lt; \u0026#34; and \u0026#34;; std::cout \u0026lt;\u0026lt; std::setw(3) \u0026lt;\u0026lt; i+1; std::cout \u0026lt;\u0026lt; \u0026#34;:\\t\u0026#34;; std::cout \u0026lt;\u0026lt; std::setw(4) \u0026lt;\u0026lt; std::setprecision(2) \u0026lt;\u0026lt; (posterior[i]); std::cout \u0026lt;\u0026lt; std::endl; } gsl_rng_free (r); return 0; } ","permalink":"https://dschrempf.github.io/coding/2015-01-15-mcmc-coin-toss/","tags":null,"title":"A simple MCMC simulation"},{"categories":["Linux"],"contents":"Did you ever need to calculate the time difference between two consecutive time stamps from a log file or something similar? Check out dateutils, it is really useful:\nddiff -i \u0026#39;%H:%M:%S\u0026#39; \u0026#39;19:09:43,683\u0026#39; \u0026#39;19:34:10,350\u0026#39; ","permalink":"https://dschrempf.github.io/linux/2015-01-07-dateutils/","tags":null,"title":"Dateutils"},{"categories":["Linux"],"contents":"Working with large files takes a long time. Sometimes, it is worth to zip folders individually, so that a single archive does not get too large. GNU Parallel is a shell tool to execute jobs in parallel. Here, I show one of possibly many methods to use it to zip many folders (or files) in parallel.\nCreate a file with all folders that you want to zip, e.g with: ls -1 \u0026gt; folders Use GNU Parallel to zip them: parallel -a folders \u0026#34;tar -czf {}.tar.gz {}\u0026#34; In order to unzip many files at ones (this method can also be used to zip the files if their names follow certain patterns):\nparallel \u0026#34;tar -xzf {}\u0026#34; ::: *.tar.gz ","permalink":"https://dschrempf.github.io/linux/2015-01-07-gnu-parallel/","tags":null,"title":"Zip folders with GNU Parallel"},{"categories":["Emacs"],"contents":"This homepage was created with Emacs and Org mode. It is hosted at github.io and comments can be done using Disqus. I assume a working Org mode setup and a GitHub as well as a Disqus account.\n[2015-03-26 Thu] Update; general revision of code and text.\n[2016-04-09 Sat] Another update.\nGeneral idea Org mode A great tool for taking notes and exporting them to all kind of formats. One of this formats is HTML. The idea here is to use the publishing capabilities of Org mode to create a very basic website that can be used to blog and publish articles. GitHub Offers a freely available hosting service, a very easy way to make the website available. Disqus Provides the ability to comment posts. Many people also use Jekyll to create homepages and blogs together with Org mode and GitHub. This is certainly a very appealing alternative but I prefer a setting that is easier to set up and has fewer options.\nFolder structure I decided to use the following folder structure; it is somehow arbitrary but the Org mode publishing setup has to be adjusted accordingly:\n/home/dominik/Shared/blog ├── dschrempf.github.io └── org ├── css ├── js └── posts 8 directories The folders css and js are self explanatory. Good style sheets are hard to get. I use a neat one from Worg with a few changes. For this setup, it has to be saved as /blog/org/css/site.css. dschrempf.github.io is the git repository of the GitHub homepage (there are detailed explanations on GitHub about how to set it up). The posts created with Org mode reside in the org directory. It is important that you create an index.org file because GitHub is looking for an index.html file and displays it as the main page. You can use all capabilities of Org mode and its export and publishing framework.\nOrg Mode publishing setup This is the main step. Org mode has to know how to export your Org files so that they can be hosted by GitHub:\n(setq org-publish-project-alist \u0026#39;( ;; Blog posts in Org mode that are exported to html and hosted ;; by GitHub. (\u0026#34;blog\u0026#34; ;; Directory with Org files. :base-directory \u0026#34;~/Shared/blog/org/\u0026#34; :base-extension \u0026#34;org\u0026#34; ;; Output directory for html files on GitHub. :publishing-directory \u0026#34;~/Shared/blog/dschrempf.github.io/\u0026#34; :publishing-function (org-html-publish-to-html) :html-extension \u0026#34;html\u0026#34; ;; Create a sitemap that contains all posts in ;; anti-chronological order. :auto-sitemap t :sitemap-filename \u0026#34;archive.org\u0026#34; :sitemap-title \u0026#34;Archive\u0026#34; :sitemap-sort-files anti-chronologically :sitemap-style list :recursive t :section-numbers nil :with-toc t ;; Do not include predefined header scripts. :html-head-include-default-style nil :html-head-include-scripts nil :html-head \u0026#34;\u0026lt;link rel=\u0026#39;stylesheet\u0026#39; href=\u0026#39;/css/site.css\u0026#39; type=\u0026#39;text/css\u0026#39;/\u0026gt; \u0026lt;meta name=\\\u0026#34;viewport\\\u0026#34; content=\\\u0026#34;width=device-width\\\u0026#34;/\u0026gt;\u0026#34; :html-preamble website-html-preamble :html-postamble website-html-postamble :html-link-home \u0026#34;http://dschrempf.github.io/\u0026#34; :html-link-use-abs-url nil) (\u0026#34;static\u0026#34; :base-directory \u0026#34;~/Shared/blog/org/\u0026#34; :base-extension \u0026#34;css\\\\|js\\\\|jpg\\\\|gif\\\\|png\\\\|pdf\\\\|mp3\\\\|ogg\\\\|swf\u0026#34; :publishing-directory \u0026#34;~/Shared/blog/dschrempf.github.io/\u0026#34; :publishing-function org-publish-attachment :recursive t) ;; (\u0026#34;website\u0026#34; :components (\u0026#34;blog\u0026#34; \u0026#34;images\u0026#34; \u0026#34;js\u0026#34; \u0026#34;css\u0026#34;)))) (\u0026#34;website\u0026#34; :components (\u0026#34;blog\u0026#34; \u0026#34;static\u0026#34;)))) This defines a set of projects that can be published simultaneously with the project website (e.g. with M-x org-publish website). The preamble includes a small header; the postamble includes the Disqus comment section and Google Analytics (make sure to replace you user name and tracking ID).\n;; BugFix: Manually disable home/up links in preamble. (setq org-html-home/up-format \u0026#34;\u0026#34;) (defun website-html-preamble (info) \u0026#34;Org-mode website HTML export preamble.\u0026#34; (format \u0026#34;\u0026lt;div class=\u0026#39;nav\u0026#39;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#39;/\u0026#39;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#39;/archive.html\u0026#39;\u0026gt;Archive\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt;\u0026#34;)) (defun website-html-postamble (info) \u0026#34;Put Disqus into Org mode website postamble. Do not show disqus for the Archive and the Index.\u0026#34; (concat (cond ((string= (car (plist-get info :title)) \u0026#34;Archive\u0026#34;) \u0026#34;\u0026#34;) ((string= (car (plist-get info :title)) \u0026#34;Index\u0026#34;) \u0026#34;\u0026#34;) ((string= (car (plist-get info :title)) \u0026#34;GitHub -\u0026gt; IO ()\u0026#34;) \u0026#34;\u0026#34;) (t \u0026#34;\u0026lt;div id=\u0026#39;disqus_thread\u0026#39;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#39;text/javascript\u0026#39;\u0026gt; // required: replace example with your forum shortname var disqus_shortname = \u0026#39;YOUR DISQUS NAME HERE\u0026#39;; (function() { var dsq = document.createElement(\u0026#39;script\u0026#39;); dsq.type = \u0026#39;text/javascript\u0026#39;; dsq.async = true; dsq.src = \u0026#39;//\u0026#39; + disqus_shortname + \u0026#39;.disqus.com/embed.js\u0026#39;; (document.getElementsByTagName(\u0026#39;head\u0026#39;)[0] || document.getElementsByTagName(\u0026#39;body\u0026#39;)[0]).appendChild(dsq); })(); \u0026lt;/script\u0026gt; \u0026lt;noscript\u0026gt;\u0026lt;p\u0026gt;Please enable JavaScript to view the \u0026lt;a href=\u0026#39;http://disqus.com/?ref_noscript\u0026#39;\u0026gt;comments powered by Disqus.\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/noscript\u0026gt;\u0026#34;)) (format \u0026#34;\u0026lt;div class=\u0026#39;footer\u0026#39;\u0026gt; Copyright 2014 AUTHOR\u0026lt;br/\u0026gt; Last updated %s \u0026lt;br/\u0026gt; Built with %s \u0026lt;br/\u0026gt; %s HTML \u0026lt;/div\u0026gt; \u0026lt;script type=\u0026#39;text/javascript\u0026#39;\u0026gt; (function(i,s,o,g,r,a,m){i[\u0026#39;GoogleAnalyticsObject\u0026#39;]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\u0026#39;script\u0026#39;,\u0026#39;//www.google-analytics.com/analytics.js\u0026#39;,\u0026#39;ga\u0026#39;); ga(\u0026#39;create\u0026#39;, \u0026#39;PUT YOUR TRACKING ID HERE\u0026#39;, \u0026#39;auto\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt;\u0026#34; (format-time-string \u0026#34;%Y-%m-%d\u0026#34;) org-html-creator-string org-html-validation-link))) Workflow Create your homepages with Emacs Org mode. The index.org file can include links to all blog articles. Links, source blocks, images and so on can be used everywhere. This is explained in great detail on the Org mode homepage. Publish the homepage with org-publish (i.e., bind this to a key) and push the changes to GitHub. Voila!\n","permalink":"https://dschrempf.github.io/emacs/2014-12-26-how-to-create-this-homepage/","tags":null,"title":"How to create this homepage"},{"categories":null,"contents":"\nPostdoc in Computational Biology\nEötvös Loránd University, Budapest\nInterests Functional Programming (Haskell) Software engineering Markov Chains Data science Computational biology Education PhD in Computational Biology, Vienna University of Veterinary Medicine, 2017 MSc in Physics, Vienna University of Technology, 2013 About I am a postdoctoral researcher and software engineer in computational biology with 15 years of experience in programming in Haskell. I have applied my programming skills in a wide array of topics ranging from physics and biology to finance.\n","permalink":"https://dschrempf.github.io/about/","tags":null,"title":"Dominik Schrempf"},{"categories":["Coding"],"contents":"I repeatedly struggle with GHCi when I want to print lists and maps and actually look at them and analyze them. Today I came accross pretty-show, a haskell package that allows pretty printing of all objects that are instances of the type class Show.\nThe usage is very straight forward:\nimport qualified Text.Show.Pretty as Pr This provides Pr.ppShow which can be used in GHCi (or other interpreters):\nputStrLn $ Pr.ppShow object ","permalink":"https://dschrempf.github.io/coding/2014-12-23-haskell-pretty-print/","tags":null,"title":"Easy pretty print in Haskell"},{"categories":null,"contents":"I license the content of the website under the GNU General Public License v3.0.\nI build the website with Emacs, Org Mode, Hugo, and ox-hugo. I use the theme Skeria. Please refer to the licenses of these projects on the linked websites.\nI provide the source code of this homepage on GitHub.\n","permalink":"https://dschrempf.github.io/license/","tags":null,"title":"License"}]