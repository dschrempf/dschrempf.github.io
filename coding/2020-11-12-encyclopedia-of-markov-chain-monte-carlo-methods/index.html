

<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">

    <head>
        <meta http-equiv="content-type" content="text/html; charset=utf-8">

        
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

        
        <title>Encyclopedia of Markov chain Monte Carlo methods &middot; Dominik Schrempf</title>
        <meta name="description" content="In the MCMC community, many people call the same concepts by different names">
        <meta name="keywords" content="Markov chain Monte Carlo,Metropolis-Hastings,Metropolis-Hastings-Green,Population based methods">

        
        <link rel="stylesheet" href="https://dschrempf.github.io/css/skeria.css">

        
        <link rel="preconnect" href="https://fonts.gstatic.com">
        <link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@400;700&family=Inconsolata:wght@400;700&display=swap" rel="stylesheet">
        

        
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.1/css/academicons.min.css" />

        
        <link rel="stylesheet" type="text/css" href="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.css" />
        <script src="//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.1/cookieconsent.min.js"></script>
        <script>
         window.addEventListener("load", function(){
             window.cookieconsent.initialise({
                 "palette": {
                     "popup": {
                         "background": "#000"
                     },
                     "button": {
                         "background": "#f1d600"
                     }
                 }
             })});
        </script>
    </head>

    <body>
        <div class="topbar">
    <div class="topbar-sticky">
        <a href="https://dschrempf.github.io/"
   style="text-decoration: none">
    <h1>Concept â†’ IO ()</h1>
</a>

        <span class="lead">Articles about coding and music.</span>
        <span class="topbar-nav">
    <p>
        
        <span class="topbar-nav-item">
            <a href="https://dschrempf.github.io/linux/">Linux</a>
        </span>
        
        <span class="topbar-nav-item">
            <a href="https://dschrempf.github.io/emacs/">Emacs</a>
        </span>
        
        <span class="topbar-nav-item">
            <a href="https://dschrempf.github.io/coding/">Coding</a>
        </span>
        
        <span class="topbar-nav-item">
            <a href="https://dschrempf.github.io/music/">Music</a>
        </span>
        
        
        <span class="topbar-nav-item">
            <a href="https://dschrempf.github.io/links/">Links</a>
        </span>
        
        <span class="topbar-nav-item">
            <a href="https://dschrempf.github.io/about/">About</a>
        </span>
        
        
        <span class="topbar-nav-item">
            <a href="https://dschrempf.github.io/search/">Search</a>
        </span>
        
    </p>
</span>

    </div>
</div>


        
        

        
        
<div class="content container">
  <div class="post">
    <h1 class="post-title">Encyclopedia of Markov chain Monte Carlo methods</h1>
    <span class="post-date">
        Dec 18, 2020
        &middot; 5 minute read
        
        &middot;
        
        <a class="label" href="https://dschrempf.github.io/coding">Coding</a>
        
        
    </span>
    <p>I started this encyclopedic overview because in the Markov chain Monte Carlo
(MCMC) community many people call the same or similar concepts by very different
names. Please let me know, if you have suggestions or comments, or if you would
like to add some definitions or synonyms to this overview.</p>
<h2 id="bibliography">Bibliography</h2>
<h3 id="books">Books</h3>
<ul>
<li>The nomenclature here is taken from the excellent introduction to Markov chain
Monte Carlo (MCMC) methods by <sup id="676b94678a2d6c9d04a9b66e91b82cd3"><a href="#Geyer2011" title="@InCollection{    Geyer2011,
Author        = {Geyer, Charles J},
Title         = {{Introduction to Markov Chain Monte Carlo}},
BookTitle     = {{Handbook of Markov Chain Monte Carlo}},
Publisher     = {CRC press},
Year          = 2011,
Pages         = 45
}">Geyer2011</a></sup>, Chapter 1 in
<sup id="e1e37a8427e438f2177e7c707a2f8694"><a href="#Brooks2011" title="Brooks, Gelman, Jones, \&amp; Meng, {Handbook of Markov Chain Monte Carlo}, CRC press (2011).">Brooks2011</a></sup>.</li>
<li>More advanced topics such as population based MCMC methods are covered in
<sup id="b5a706697adb263d73098e60072ae11d"><a href="#Liang2011" title="Liang, Liu \&amp; Carroll, Advanced Markov chain Monte Carlo methods: learning from  past samples, John Wiley \&amp; Sons (2011).">Liang2011</a></sup>.</li>
<li>See <sup id="9207e829ab55aba29074181b4b770dd6"><a href="#Doucet2001" title="Sequential Monte Carlo Methods in Practice, Springer New York (2001).">Doucet2001</a></sup> for sequential Monte Carlo algorithms.</li>
</ul>
<h3 id="articles">Articles</h3>
<ul>
<li><sup id="f0227103734119b77f5580811b6f3205"><a href="#Gilks2001" title="Walter Gilks \&amp; Carlo Berzuini, Following a Moving Target-Monte Carlo Inference for  Dynamic Bayesian Models, {Journal of the Royal Statistical Society. Series B
(Statistical Methodology)}, v(1), 127--146 (2001).">Gilks2001</a></sup></li>
<li><sup id="0ab33258c70dc93da405dceb25d5c9c9"><a href="#DelMoral2006" title="Del Moral, Doucet \&amp; Jasra, Sequential Monte Carlo samplers, {Journal of the Royal Statistical Society: Series B
(Statistical Methodology)}, v(3), 411--436 (2006).">DelMoral2006</a></sup></li>
<li><sup id="7a29f5f0390cfe4b9879af8fe6394cfd"><a href="#Andrieu2010" title="Andrieu, Doucet, Holenstein \&amp; Roman, Particle Markov chain Monte Carlo methods, {Journal of the Royal Statistical Society: Series B
(Statistical Methodology)}, v(3), 269--342 (2010).">Andrieu2010</a></sup></li>
<li><sup id="54b61d4f223d48473b86320c0a4d367e"><a href="#Doucet2011" title="@InCollection{    Doucet2011,
Author        = {A. {Doucet} and A. M. {Johansen}},
Title         = {{A tutorial on particle filtering and smoothing: fifteen
years later}},
BookTitle     = {{The Oxford handbook of nonlinear filtering}},
Publisher     = {Oxford: Oxford University Press},
Year          = 2011,
Pages         = {656--704},
msc2010       = {62M10}
}">Doucet2011</a></sup></li>
<li><sup id="0529e4756add5da79b1f4eef5589b43f"><a href="#Chopin2012" title="Chopin, Jacob \&amp; Papaspiliopoulos, SMC2: an efficient algorithm for sequential analysis of  state space models, {Journal of the Royal Statistical Society: Series B
(Statistical Methodology)}, v(3), 397--426 (2012).">Chopin2012</a></sup></li>
<li><sup id="75ffedaf2627a4fcdfe80e3118ce6fcf"><a href="#Heng2020" title="Heng, Bishop, Deligiannidis, George \&amp; Doucet, Controlled sequential Monte Carlo, {Annals of Statistics}, v(5), 2904--2929 (2020).">Heng2020</a></sup></li>
</ul>
<h3 id="articles-tailored-to-a-phylogenetic-audience">Articles tailored to a phylogenetic audience</h3>
<ul>
<li><sup id="a6376643b744242fb6bba104f05712f2"><a href="#BouchardCote2012" title="Bouchard-C&#244;t&#233;, Sankararaman, \&amp; Jordan, Phylogenetic inference via sequential monte carlo, {Systematic Biology}, v(4), 579--593 (2012).">BouchardCote2012</a></sup></li>
<li><sup id="e8d23a1c69bc73198a7ec34c97f9d193"><a href="#Dinh2018" title="Vu Dinh, Aaron E Darling \&amp; Frederick A Matsen IV, Online Bayesian phylogenetic inference: theoretical  foundations via sequential Monte Carlo, {Systematic Biology}, v(3), 503--517 (2018).">Dinh2018</a></sup></li>
<li><sup id="5fd71a0f12feaf6490542a96b3c163cb"><a href="#Fourment2018" title="Mathieu Fourment, Brian Claywell, Vu Dinh, , Connor McCoy, Frederick Matsen IV, Aaron \&amp; Darling, Effective online bayesian phylogenetics via sequential  monte carlo with guided proposals, {Systematic Biology}, v(3), 490--502 (2018).">Fourment2018</a></sup></li>
</ul>
<h2 id="necessary-definitions">Necessary definitions</h2>
<p><strong>Elementary updates</strong> are instructions about how to advance a Markov chain so
that it possibly reaches a new state. That is, elementary updates specify how
the chain traverses the state space. Elementary updates cannot be decomposed
into smaller updates.</p>
<p>Elementary updates can be combined to form composite updates, a technique often
referred to as <strong>composition</strong>. We use the word <strong>update</strong> to refer to either an
elementary or a composite update.</p>
<p>Updates can also be executed in random order, a technique often referred to as
<strong>mixture</strong>. Here, the word mixture is used in the sense of mixture models, and
not in the sense of a chain reaching convergence.</p>
<p>The <strong>composition</strong> and <strong>mixture</strong> of elementary updates allows the specification
of all (Is this true?, Please correct me if it is not.) MCMC algorithms
involving a single chain. In particular, Gibbs samplers of all sorts can be
specified using this procedure.</p>
<p>Roughly, a <strong>Markov kernel</strong> is a map describing the probability density (for
continuous spaces) or the probability mass (for discrete spaces) of updating one
state to another.</p>
<p>The <strong>Metropolis-Hasings-Green</strong> algorithm specifies the acceptance probability of
updates so that the stationary distribution of the resulting Markov chain is the
desired posterior distribution.</p>
<p>Many methods to improve convergence of MCMC samplers have been designed. Most
notably, we have methods involving <strong>auxiliary variables</strong> and <strong>population based</strong>
methods running various MCMC samplers in parallel.</p>
<h2 id="unnecessary-synonyms">Unnecessary synonyms</h2>
<dl>
<dt>Proposal</dt>
<dd>Update.</dd>
<dt>Move</dt>
<dd>Update.</dd>
<dt>Metropolis update</dt>
<dd>Update with uniform Markov kernel.</dd>
<dt>Metropolis-Hastings update</dt>
<dd>Update with arbitrary Markov kernel.</dd>
</dl>
<h2 id="unnecessary-synonyms-and-special-cases-of-metropolis-hastings-green-mcmc-methods">Unnecessary synonyms and special cases of Metropolis-Hastings-Green MCMC methods</h2>
<dl>
<dt>Fixed scan algorithm</dt>
<dd>MCMC sampler involving composition.</dd>
<dt>Random scan algorithm</dt>
<dd>MCMC sampler involving mixture.</dd>
<dt>Random sequence scan algorithm</dt>
<dd>MCMC sampler involving composition and mixture.</dd>
<dt>Gibbs update</dt>
<dd>Update with Metropolis-Hastings ratio of 1.0. That is, Gibbs
updates are always accepted. Gibbs updates can be designed using conditional
Markov kernels.</dd>
<dt>Gibbs sampler</dt>
<dd>MCMC sampler in which all of the elementary updates are
Gibbs, combined either by composition (fixed scan), by mixture (random scan),
or both (random sequence scan).</dd>
<dt>Metropolis algorithm</dt>
<dd>MCMC sampler in which all of the elementary updates
are Metropolis, combined either by composition, mixture, or both (and the same
&ldquo;scan&rdquo; terminology is used).</dd>
<dt>Metropolis-Hastings algorithm</dt>
<dd>MCMC sampler in which all of the elementary
updates are Metropolis-Hastings, combined either by composition, mixture, or
both (and the same &ldquo;scan&rdquo; terminology is used).</dd>
<dt>Metropolis-within-Gibbs sampler</dt>
<dd>The same as the preceding item. This name
makes no sense at all since Gibbs is a special case of Metropolis-Hastings.</dd>
<dt>Independence Metropolis-Hastings algorithm</dt>
<dd>Special case of the
Metropolis-Hastings algorithm in which the Markov kernel does not depend on
the current state: \(q(x, \cdot)\) does not depend on \(x\).</dd>
<dt>Random-walk Metropolis-Hastings algorithm</dt>
<dd>Special case of the
Metropolis-Hastings algorithm in which the proposal has the form \(x+e\),
where \(e\) is stochastically independent of the current state \(x\), so
\(q(x, y\) has the form \(f(y-x)\).</dd>
<dt>Reversible jump MCMC algorithm</dt>
<dd>MCMC sampler including updates between
different models possibly having a different set of parameters. However, these
updates are in no way special.</dd>
</dl>
<h2 id="special-cases-of-auxiliary-variable-mcmc-methods">Special cases of auxiliary variable MCMC methods</h2>
<ul>
<li>Data augmentation.</li>
<li>Simulated annealing.</li>
<li>Simulated tempering.</li>
</ul>
<h2 id="special-cases-of-population-based-mcmc-methods">Special cases of population based MCMC methods</h2>
<ul>
<li>Sequential Monte Carlo.</li>
<li>Parallel tempering.</li>
<li>Metropolic-coupled MCMC (MC3) is Parallel tempering.</li>
</ul>
<h1 id="bibliography-1">Bibliography</h1>
<p><a id="Geyer2011"></a>[Geyer2011] @InCollection    Geyer2011,
Author        = Geyer, Charles J,
Title         = Introduction to Markov Chain Monte Carlo,
BookTitle     = Handbook of Markov Chain Monte Carlo,
Publisher     = CRC press,
Year          = 2011,
Pages         = 45
<a href="#676b94678a2d6c9d04a9b66e91b82cd3">â†©</a></p>
<p><a id="Brooks2011"></a>[Brooks2011] Brooks, Gelman, Jones, &amp; Meng, Handbook of Markov Chain Monte Carlo, CRC press (2011). <a href="#e1e37a8427e438f2177e7c707a2f8694">â†©</a></p>
<p><a id="Liang2011"></a>[Liang2011] Liang, Liu &amp; Carroll, Advanced Markov chain Monte Carlo methods: learning from  past samples, John Wiley &amp; Sons (2011). <a href="#b5a706697adb263d73098e60072ae11d">â†©</a></p>
<p><a id="Doucet2001"></a>[Doucet2001] Sequential Monte Carlo Methods in Practice, Springer New York (2001). <a href="#9207e829ab55aba29074181b4b770dd6">â†©</a></p>
<p><a id="Gilks2001"></a>[Gilks2001] Walter Gilks &amp; Carlo Berzuini, Following a Moving Target-Monte Carlo Inference for  Dynamic Bayesian Models, <i>Journal of the Royal Statistical Society. Series B
(Statistical Methodology)</i>, <b>63(1)</b>, 127-146 (2001). <a href="#f0227103734119b77f5580811b6f3205">â†©</a></p>
<p><a id="DelMoral2006"></a>[DelMoral2006] Del Moral, Doucet &amp; Jasra, Sequential Monte Carlo samplers, <i>Journal of the Royal Statistical Society: Series B
(Statistical Methodology)</i>, <b>68(3)</b>, 411-436 (2006). <a href="http://dx.doi.org/10.1111/j.1467-9868.2006.00553.x">doi</a>. <a href="#0ab33258c70dc93da405dceb25d5c9c9">â†©</a></p>
<p><a id="Andrieu2010"></a>[Andrieu2010] Andrieu, Doucet, Holenstein &amp; Roman, Particle Markov chain Monte Carlo methods, <i>Journal of the Royal Statistical Society: Series B
(Statistical Methodology)</i>, <b>72(3)</b>, 269-342 (2010). <a href="http://dx.doi.org/10.1111/j.1467-9868.2009.00736.x">doi</a>. <a href="#7a29f5f0390cfe4b9879af8fe6394cfd">â†©</a></p>
<p><a id="Doucet2011"></a>[Doucet2011] @InCollection    Doucet2011,
Author        = A. Doucet and A. M. Johansen,
Title         = A tutorial on particle filtering and smoothing: fifteen
years later,
BookTitle     = The Oxford handbook of nonlinear filtering,
Publisher     = Oxford: Oxford University Press,
Year          = 2011,
Pages         = 656-704,
msc2010       = 62M10
<a href="#54b61d4f223d48473b86320c0a4d367e">â†©</a></p>
<p><a id="Chopin2012"></a>[Chopin2012] Chopin, Jacob &amp; Papaspiliopoulos, SMC2: an efficient algorithm for sequential analysis of  state space models, <i>Journal of the Royal Statistical Society: Series B
(Statistical Methodology)</i>, <b>75(3)</b>, 397-426 (2012). <a href="http://dx.doi.org/10.1111/j.1467-9868.2012.01046.x">doi</a>. <a href="#0529e4756add5da79b1f4eef5589b43f">â†©</a></p>
<p><a id="Heng2020"></a>[Heng2020] Heng, Bishop, Deligiannidis, George &amp; Doucet, Controlled sequential Monte Carlo, <i>Annals of Statistics</i>, <b>48(5)</b>, 2904-2929 (2020). <a href="http://dx.doi.org/10.1214/19-aos1914">doi</a>. <a href="#75ffedaf2627a4fcdfe80e3118ce6fcf">â†©</a></p>
<p><a id="BouchardCote2012"></a>[BouchardCote2012] Bouchard-CÃ´tÃ©, Sankararaman, &amp; Jordan, Phylogenetic inference via sequential monte carlo, <i>Systematic Biology</i>, <b>61(4)</b>, 579-593 (2012). <a href="http://dx.doi.org/10.1093/sysbio/syr131">doi</a>. <a href="#a6376643b744242fb6bba104f05712f2">â†©</a></p>
<p><a id="Dinh2018"></a>[Dinh2018] Vu Dinh, Aaron E Darling &amp; Frederick A Matsen IV, Online Bayesian phylogenetic inference: theoretical  foundations via sequential Monte Carlo, <i>Systematic Biology</i>, <b>67(3)</b>, 503-517 (2018). <a href="http://dx.doi.org/10.1093/sysbio/syx087">doi</a>. <a href="#e8d23a1c69bc73198a7ec34c97f9d193">â†©</a></p>
<p><a id="Fourment2018"></a>[Fourment2018] Mathieu Fourment, Brian Claywell, Vu Dinh, , Connor McCoy, Frederick Matsen IV, Aaron &amp; Darling, Effective online bayesian phylogenetics via sequential  monte carlo with guided proposals, <i>Systematic Biology</i>, <b>67(3)</b>, 490-502 (2018). <a href="http://dx.doi.org/10.1093/sysbio/syx090">doi</a>. <a href="#5fd71a0f12feaf6490542a96b3c163cb">â†©</a></p>

  </div>
  <div class="disqus" id="disqus_thread"></div>
</div>


<script id="dsq-count-scr" src="//dschrempf.disqus.com/count.js" async></script>
<script>
 var disqus_shortname = "dschrempf";
 var disqus_config = function () {
     this.page.url = "https://dschrempf.github.io/coding/2020-11-12-encyclopedia-of-markov-chain-monte-carlo-methods/";
     this.page.identifier = "Encyclopedia of Markov chain Monte Carlo methods";
 };
 (function() {
     var d = document, s = d.createElement('script');
     s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
     s.setAttribute('data-timestamp', +new Date());
     (d.head || d.body).appendChild(s);
 })();
</script>
<noscript>Please enable JavaScript to view <a href="https://disqus.com/?ref_noscript">comments.</a></noscript>





        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.3/fuse.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js"></script>

        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.1.2/es5/tex-svg.min.js" integrity="sha512-9irB0qyXMAf4xUF5UEVOhb4NMCWo7xeKakVbl0lfJ09HyhrplRCqTFMtaW6lP7G0IbHfIcmSo3dFZrWcrsGnOA==" crossorigin="anonymous"></script>

        
        <div class="bottombar">
    <div class="bottombar-sticky">
        <div class="icons">
    <span class="icons-item"> <a href="https://github.com/dschrempf" target="_blank"><i class="fab fa-github"></i></a></span>
    <span class="icons-item"> </span>
    <span class="icons-item"> <a href="https://www.stackoverflow.com/users/3536806" target="_blank"><i class="fab fa-stack-overflow fa-1x"></i></a></span>
    <span class="icons-item"> </span>
    <span class="icons-item"> </span>
    <span class="icons-item"> </span>
    <span class="icons-item"> <a href="https://twitter.com/fazky" target="_blank"><i class="fab fa-twitter fa-1x"></i></a></span>
    <span class="icons-item"> </span>
    <span class="icons-item"> <a href="https://orcid.org/0000-0001-8865-9237" target="_blank"><i class="ai ai-orcid ai-1x"></i></a></span>
    <span class="icons-item"> <a href="mailto:dominik.schrempf@gmail.com"><i class="fas fa-envelope fa-1x"></i></a></span>
    <span class="icons-item"> <a href="/gpg_public_key.txt"><i class="fas fa-key fa-1x"></i></a></span>
    <span class="icons-item"> </span>
</div>



        <div class= "footer">
    <p>
        &copy; 2021 Dominik Schrempf, <a href="https://dschrempf.github.io/license/">License</a><br/>
        Powered by <a href="https://gohugo.io">Hugo</a>, <a href="https://ox-hugo.scripter.co/">ox-hugo</a> and <a href="https://github.com/dschrempf/skeria">Skeria</a><br/>
        
        <a href="https://www.iubenda.com/privacy-policy/76967501" class="" title="Privacy Policy">Privacy Policy</a>
        
    </p>
</div>

    </div>
</div>


        
        
        
    </body>

</html>
